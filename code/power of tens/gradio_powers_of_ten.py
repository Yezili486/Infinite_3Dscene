import gradio as gr
import torch
from diffusers import StableDiffusionPipeline, DDPMScheduler
import numpy as np
import cv2
from scipy.ndimage import gaussian_filter
import warnings
import time
import io
import base64
from PIL import Image
import matplotlib.pyplot as plt
from typing import List, Tuple, Optional
import threading
import os

warnings.filterwarnings("ignore")

# è®¾å¤‡é…ç½®
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# å…¨å±€å˜é‡å­˜å‚¨å½“å‰çš„ç¼©æ”¾æ ˆ
current_zoom_stack = None
generation_status = {"status": "idle", "progress": 0, "message": ""}

# ==================== æ ¸å¿ƒåŠŸèƒ½ ====================
# (è¿™é‡ŒåŒ…å«ä¹‹å‰å®ç°çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½)

# å™ªå£°è°ƒåº¦å‚æ•°
def get_noise_schedule(num_timesteps=1000, beta_start=0.00085, beta_end=0.012):
    """è·å–å™ªå£°è°ƒåº¦å‚æ•°"""
    betas = torch.linspace(beta_start, beta_end, num_timesteps, dtype=torch.float32)
    alphas = 1.0 - betas
    alphas_cumprod = torch.cumprod(alphas, dim=0)
    
    return {
        'betas': betas,
        'alphas': alphas, 
        'alphas_cumprod': alphas_cumprod,
        'sqrt_alphas_cumprod': torch.sqrt(alphas_cumprod),
        'sqrt_one_minus_alphas_cumprod': torch.sqrt(1.0 - alphas_cumprod)
    }

noise_schedule = get_noise_schedule()

# ç¼©æ”¾æ ˆæ•°æ®ç»“æ„
class ZoomStack:
    """ç¼©æ”¾æ ˆæ•°æ®ç»“æ„"""
    
    def __init__(self, zoom_factors, H=512, W=512, device="cuda"):
        self.zoom_factors = zoom_factors
        self.N = len(zoom_factors)
        self.H = H
        self.W = W
        self.device = device
        
        # éªŒè¯ç¼©æ”¾å› å­
        for i, p in enumerate(zoom_factors):
            if i == 0:
                assert p == 1, "ç¬¬ä¸€ä¸ªç¼©æ”¾å› å­å¿…é¡»æ˜¯1"
            else:
                assert p == 2 * zoom_factors[i-1], f"ç¼©æ”¾å› å­å¿…é¡»æ˜¯2çš„å¹‚åºåˆ—"
        
        # åˆå§‹åŒ–å±‚
        self.layers = self._initialize_layers()
        
    def _initialize_layers(self):
        """ä»é«˜æ–¯å™ªå£°åˆå§‹åŒ–æ‰€æœ‰å±‚"""
        layers = []
        for i, p in enumerate(self.zoom_factors):
            layer = torch.randn(self.H, self.W, 3, device=self.device, dtype=torch.float32)
            layer = layer * 0.1  # å‡å°åˆå§‹å™ªå£°å¹…åº¦
            layers.append(layer)
        return layers
    
    def get_layer(self, i):
        """è·å–ç¬¬ i å±‚"""
        assert 0 <= i < self.N, f"å±‚ç´¢å¼• {i} è¶…å‡ºèŒƒå›´ [0, {self.N-1}]"
        return self.layers[i]
    
    def set_layer(self, i, layer):
        """è®¾ç½®ç¬¬ i å±‚"""
        assert 0 <= i < self.N, f"å±‚ç´¢å¼• {i} è¶…å‡ºèŒƒå›´ [0, {self.N-1}]"
        assert layer.shape == (self.H, self.W, 3), f"å±‚å½¢çŠ¶å¿…é¡»æ˜¯ ({self.H}, {self.W}, 3)"
        self.layers[i] = layer.to(self.device)
    
    def get_zoom_factor(self, i):
        """è·å–ç¬¬ i å±‚çš„ç¼©æ”¾å› å­"""
        return self.zoom_factors[i]
    
    def get_all_layers(self):
        """è·å–æ‰€æœ‰å±‚çš„å‰¯æœ¬"""
        return [layer.clone() for layer in self.layers]
    
    def to_image_format(self, layer_idx):
        """å°†å±‚è½¬æ¢ä¸ºå›¾åƒæ ¼å¼ [0, 1]"""
        layer = self.get_layer(layer_idx)
        return torch.clamp((layer + 1.0) / 2.0, 0.0, 1.0)

def create_zoom_stack(zoom_factors, H=512, W=512, device="cuda"):
    """åˆ›å»ºç¼©æ”¾æ ˆçš„ä¾¿æ·å‡½æ•°"""
    return ZoomStack(zoom_factors, H, W, device)

def generate_zoom_factors(N):
    """ç”Ÿæˆ N ä¸ªç¼©æ”¾å› å­ï¼š[1, 2, 4, ..., 2^{N-1}]"""
    return [2**i for i in range(N)]

# æ¸²æŸ“å‡½æ•°
def Pi_image(zoom_stack, i):
    """ä»ç¼©æ”¾æ ˆæ¸²æŸ“å›¾åƒï¼ˆç®—æ³• 1ï¼‰"""
    rendered = zoom_stack.get_layer(i).clone()
    H, W = rendered.shape[:2]
    p_i = zoom_stack.get_zoom_factor(i)
    
    # å¯¹äºæ‰€æœ‰æ›´é«˜å±‚ï¼Œä¸‹é‡‡æ ·å¹¶èåˆ
    for j in range(i + 1, zoom_stack.N):
        layer_j = zoom_stack.get_layer(j)
        p_j = zoom_stack.get_zoom_factor(j)
        
        # ä¸­å¿ƒè£å‰ª
        crop_h = H // p_j
        crop_w = W // p_j
        start_h = (H - crop_h) // 2
        start_w = (W - crop_w) // 2
        end_h = start_h + crop_h
        end_w = start_w + crop_w
        
        cropped_j = layer_j[start_h:end_h, start_w:end_w, :]
        
        # ä¸Šé‡‡æ ·
        cropped_j_chw = cropped_j.permute(2, 0, 1).unsqueeze(0)
        upsampled_j = torch.nn.functional.interpolate(
            cropped_j_chw, 
            size=(H, W), 
            mode='bilinear', 
            align_corners=False
        )
        upsampled_j = upsampled_j.squeeze(0).permute(1, 2, 0)
        
        # èåˆæ©ç 
        mask = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
        mask_h_start = (H - crop_h * p_j) // 2
        mask_w_start = (W - crop_w * p_j) // 2
        mask_h_end = mask_h_start + crop_h * p_j
        mask_w_end = mask_w_start + crop_w * p_j
        
        mask[mask_h_start:mask_h_end, mask_w_start:mask_w_end, :] = 1.0
        rendered = rendered * (1 - mask) + upsampled_j * mask
    
    return rendered

def Pi_noise(zoom_stack, i):
    """ä»ç¼©æ”¾æ ˆæ¸²æŸ“å™ªå£°ï¼ˆç®—æ³• 1ï¼‰"""
    H, W = zoom_stack.H, zoom_stack.W
    rendered_noise = torch.zeros((H, W, 3), device=zoom_stack.device, dtype=torch.float32)
    p_i = zoom_stack.get_zoom_factor(i)
    total_variance = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
    
    for j in range(i, zoom_stack.N):
        p_j = zoom_stack.get_zoom_factor(j)
        noise_scale = p_j / p_i
        
        if j == i:
            layer_noise = torch.randn((H, W, 3), device=zoom_stack.device, dtype=torch.float32)
            layer_noise *= noise_scale
            mask = torch.ones((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
        else:
            crop_h = H // p_j
            crop_w = W // p_j
            
            cropped_noise = torch.randn((crop_h, crop_w, 3), device=zoom_stack.device, dtype=torch.float32)
            cropped_noise *= noise_scale
            
            cropped_noise_chw = cropped_noise.permute(2, 0, 1).unsqueeze(0)
            upsampled_noise = torch.nn.functional.interpolate(
                cropped_noise_chw,
                size=(H, W),
                mode='bilinear',
                align_corners=False
            )
            layer_noise = upsampled_noise.squeeze(0).permute(1, 2, 0)
            
            mask = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
            mask_h_start = (H - crop_h * p_j) // 2
            mask_w_start = (W - crop_w * p_j) // 2
            mask_h_end = mask_h_start + crop_h * p_j
            mask_w_end = mask_w_start + crop_w * p_j
            mask[mask_h_start:mask_h_end, mask_w_start:mask_w_end, :] = 1.0
            layer_noise = layer_noise * mask
        
        rendered_noise += layer_noise
        total_variance += mask * (noise_scale ** 2)
    
    std_dev = torch.sqrt(total_variance + 1e-8)
    rendered_noise = rendered_noise / std_dev
    
    return rendered_noise

# ç®€åŒ–çš„é‡‡æ ·å‡½æ•°
def joint_multi_scale_sampling_simple(prompts, zoom_factors, T=20, H=256, W=256):
    """ç®€åŒ–ç‰ˆæœ¬çš„è”åˆå¤šå°ºåº¦é‡‡æ ·"""
    global generation_status
    
    generation_status["status"] = "generating"
    generation_status["progress"] = 0
    generation_status["message"] = "åˆå§‹åŒ–ç¼©æ”¾æ ˆ..."
    
    N = len(prompts)
    zoom_stack = create_zoom_stack(zoom_factors, H, W, device)
    
    # ç®€åŒ–çš„æ‰©æ•£å¾ªç¯
    for t in range(T, 0, -1):
        progress = (T - t + 1) / T
        generation_status["progress"] = int(progress * 100)
        generation_status["message"] = f"é‡‡æ ·æ­¥éª¤ {T-t+1}/{T}"
        
        # 1. æ¸²æŸ“å½“å‰çŠ¶æ€
        z_t_list = []
        for i in range(N):
            img_rendered = Pi_image(zoom_stack, i)
            noise_rendered = Pi_noise(zoom_stack, i)
            
            noise_level = t / T
            z_t = img_rendered + noise_level * noise_rendered * 0.3
            z_t_list.append(z_t)
        
        # 2. æ¨¡æ‹Ÿæ¨¡å‹é¢„æµ‹
        x_hat_list = []
        for i in range(N):
            denoising_strength = progress
            
            # æ·»åŠ åŸºäºæç¤ºçš„å†…å®¹æ¨¡å¼
            content_pattern = torch.sin(torch.linspace(0, 2*torch.pi*i, H*W, device=device)).reshape(H, W, 1)
            content_pattern = content_pattern.repeat(1, 1, 3) * 0.2
            
            base_img = zoom_stack.get_layer(i)
            x_hat = (base_img * (1 - denoising_strength) + 
                    content_pattern * denoising_strength * 0.5 +
                    z_t_list[i] * denoising_strength * 0.5)
            
            x_hat_list.append(x_hat)
        
        # 3. æ›´æ–°ç¼©æ”¾æ ˆ
        for i in range(N):
            zoom_stack.set_layer(i, x_hat_list[i])
    
    generation_status["status"] = "completed"
    generation_status["progress"] = 100
    generation_status["message"] = "ç”Ÿæˆå®Œæˆ!"
    
    return zoom_stack

# ==================== Gradio ç•Œé¢å‡½æ•° ====================

def tensor_to_pil(tensor):
    """å°†PyTorchå¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ"""
    # è½¬æ¢åˆ°[0, 1]èŒƒå›´
    img_tensor = torch.clamp((tensor + 1.0) / 2.0, 0.0, 1.0)
    # è½¬æ¢ä¸ºnumpy
    img_numpy = (img_tensor.cpu().numpy() * 255).astype(np.uint8)
    # è½¬æ¢ä¸ºPILå›¾åƒ
    pil_img = Image.fromarray(img_numpy)
    return pil_img

def parse_prompts(prompts_text):
    """è§£ææç¤ºæ–‡æœ¬"""
    if not prompts_text.strip():
        return []
    
    # æŒ‰è¡Œåˆ†å‰²æˆ–æŒ‰é€—å·åˆ†å‰²
    if '\n' in prompts_text:
        prompts = [p.strip() for p in prompts_text.split('\n') if p.strip()]
    else:
        prompts = [p.strip() for p in prompts_text.split(',') if p.strip()]
    
    return prompts

def parse_zoom_factors(zoom_factors_text):
    """è§£æç¼©æ”¾å› å­"""
    try:
        if not zoom_factors_text.strip():
            return []
        
        # æ”¯æŒå¤šç§æ ¼å¼
        zoom_factors_text = zoom_factors_text.replace('[', '').replace(']', '').replace('(', '').replace(')', '')
        factors = [int(f.strip()) for f in zoom_factors_text.split(',') if f.strip()]
        
        # éªŒè¯æ˜¯å¦æ˜¯2çš„å¹‚åºåˆ—
        if factors and factors[0] != 1:
            raise ValueError("ç¬¬ä¸€ä¸ªç¼©æ”¾å› å­å¿…é¡»æ˜¯1")
        
        for i in range(1, len(factors)):
            if factors[i] != 2 * factors[i-1]:
                raise ValueError("ç¼©æ”¾å› å­å¿…é¡»æ˜¯2çš„å¹‚åºåˆ—")
        
        return factors
    except Exception as e:
        raise ValueError(f"ç¼©æ”¾å› å­æ ¼å¼é”™è¯¯: {e}")

def generate_zoom_stack(prompts_text, zoom_factors_text, progress=gr.Progress()):
    """ç”Ÿæˆç¼©æ”¾æ ˆ"""
    global current_zoom_stack
    
    try:
        # è§£æè¾“å…¥
        prompts = parse_prompts(prompts_text)
        zoom_factors = parse_zoom_factors(zoom_factors_text)
        
        if not prompts:
            return "é”™è¯¯ï¼šè¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæç¤º", None, gr.update(visible=False)
        
        if not zoom_factors:
            return "é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„ç¼©æ”¾å› å­", None, gr.update(visible=False)
        
        if len(prompts) != len(zoom_factors):
            return f"é”™è¯¯ï¼šæç¤ºæ•°é‡({len(prompts)})ä¸ç¼©æ”¾å› å­æ•°é‡({len(zoom_factors)})ä¸åŒ¹é…", None, gr.update(visible=False)
        
        # ç”Ÿæˆç¼©æ”¾æ ˆ
        progress(0, desc="å¼€å§‹ç”Ÿæˆ...")
        
        # ä½¿ç”¨çº¿ç¨‹æ¥ç›‘æ§è¿›åº¦
        def monitor_progress():
            while generation_status["status"] == "generating":
                progress(generation_status["progress"] / 100, desc=generation_status["message"])
                time.sleep(0.1)
        
        monitor_thread = threading.Thread(target=monitor_progress)
        monitor_thread.start()
        
        current_zoom_stack = joint_multi_scale_sampling_simple(
            prompts=prompts,
            zoom_factors=zoom_factors,
            T=15,  # å‡å°‘æ­¥æ•°ä»¥æé«˜äº¤äº’æ€§
            H=512, W=512
        )
        
        monitor_thread.join()
        progress(1.0, desc="ç”Ÿæˆå®Œæˆ!")
        
        # è¿”å›ç¬¬ä¸€å±‚å›¾åƒä½œä¸ºé¢„è§ˆ
        first_layer_img = Pi_image(current_zoom_stack, 0)
        preview_img = tensor_to_pil(first_layer_img)
        
        # æ›´æ–°æ»‘å—èŒƒå›´
        slider_update = gr.update(
            minimum=0, 
            maximum=len(zoom_factors)-1, 
            value=0, 
            step=1,
            visible=True,
            label=f"ç¼©æ”¾çº§åˆ« (0-{len(zoom_factors)-1})"
        )
        
        return f"âœ… æˆåŠŸç”Ÿæˆ {len(zoom_factors)} å±‚ç¼©æ”¾æ ˆï¼", preview_img, slider_update
        
    except Exception as e:
        return f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}", None, gr.update(visible=False)

def render_scale_image(scale_idx):
    """æ¸²æŸ“æŒ‡å®šå°ºåº¦çš„å›¾åƒ"""
    global current_zoom_stack
    
    if current_zoom_stack is None:
        return None, "è¯·å…ˆç”Ÿæˆç¼©æ”¾æ ˆ"
    
    try:
        scale_idx = int(scale_idx)
        if scale_idx < 0 or scale_idx >= current_zoom_stack.N:
            return None, f"å°ºåº¦ç´¢å¼•è¶…å‡ºèŒƒå›´ (0-{current_zoom_stack.N-1})"
        
        # æ¸²æŸ“å›¾åƒ
        rendered_img = Pi_image(current_zoom_stack, scale_idx)
        pil_img = tensor_to_pil(rendered_img)
        
        zoom_factor = current_zoom_stack.get_zoom_factor(scale_idx)
        info_text = f"å°ºåº¦ {scale_idx}: ç¼©æ”¾å› å­ {zoom_factor}x"
        
        return pil_img, info_text
        
    except Exception as e:
        return None, f"æ¸²æŸ“å¤±è´¥: {str(e)}"

def create_zoom_animation():
    """åˆ›å»ºç¼©æ”¾åŠ¨ç”»"""
    global current_zoom_stack
    
    if current_zoom_stack is None:
        return None, "è¯·å…ˆç”Ÿæˆç¼©æ”¾æ ˆ"
    
    try:
        print("å¼€å§‹åˆ›å»ºç¼©æ”¾åŠ¨ç”»...")
        
        # åˆ›å»ºåŠ¨ç”»å¸§
        frames = []
        for i in range(current_zoom_stack.N):
            rendered_img = Pi_image(current_zoom_stack, i)
            pil_img = tensor_to_pil(rendered_img)
            frames.append(pil_img)
        
        # ä¿å­˜ä¸ºGIF
        if frames:
            output_path = "zoom_animation.gif"
            frames[0].save(
                output_path,
                save_all=True,
                append_images=frames[1:],
                duration=1000,  # æ¯å¸§1ç§’
                loop=0
            )
            
            print(f"åŠ¨ç”»å·²ä¿å­˜: {output_path}")
            return output_path, f"âœ… åŠ¨ç”»å·²åˆ›å»ºï¼ŒåŒ…å« {len(frames)} å¸§"
        else:
            return None, "âŒ æ— æ³•åˆ›å»ºåŠ¨ç”»å¸§"
            
    except Exception as e:
        print(f"åŠ¨ç”»åˆ›å»ºå¤±è´¥: {e}")
        return None, f"âŒ åŠ¨ç”»åˆ›å»ºå¤±è´¥: {str(e)}"

def get_example_inputs():
    """è·å–ç¤ºä¾‹è¾“å…¥"""
    examples = {
        "cosmic": {
            "prompts": "distant galaxy with swirling spiral arms\nstar system with multiple planets\nplanet surface with mountains\nclose-up of alien vegetation",
            "zoom_factors": "1, 2, 4, 8"
        },
        "nature": {
            "prompts": "vast forest landscape\ntree with many branches\nbark texture detail\ninsect on bark surface",
            "zoom_factors": "1, 2, 4, 8"
        },
        "ocean": {
            "prompts": "ocean from space\nocean surface with waves\nunderwater coral reef\ntropical fish close-up",
            "zoom_factors": "1, 2, 4, 8"
        }
    }
    return examples

# ==================== Gradio ç•Œé¢ ====================

def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(
        title="Generative Powers of Ten - Interactive Demo",
        theme=gr.themes.Soft(),
        css="""
        .main-container { max-width: 1200px; margin: auto; }
        .header { text-align: center; margin-bottom: 2rem; }
        .status-text { font-weight: bold; }
        """
    ) as demo:
        
        # æ ‡é¢˜å’Œè¯´æ˜
        gr.HTML("""
        <div class="header">
            <h1>ğŸ” Generative Powers of Ten - Interactive Demo</h1>
            <p>åŸºäºè®ºæ–‡ "Generative Powers of Ten" çš„äº¤äº’å¼æ¼”ç¤º</p>
            <p>è¾“å…¥æ–‡æœ¬æç¤ºç”Ÿæˆå¤šå°ºåº¦ç¼©æ”¾æ ˆï¼Œå¹¶å®æ—¶æµè§ˆä¸åŒç¼©æ”¾çº§åˆ«çš„å›¾åƒ</p>
        </div>
        """)
        
        with gr.Row():
            # å·¦ä¾§ï¼šè¾“å…¥æ§åˆ¶é¢æ¿
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“ è¾“å…¥é…ç½®")
                
                prompts_input = gr.Textbox(
                    label="æ–‡æœ¬æç¤º (æ¯è¡Œä¸€ä¸ªæˆ–é€—å·åˆ†éš”)",
                    placeholder="ä¾‹å¦‚ï¼š\ndistant galaxy\nstar system\nplanet surface\ninsect detail",
                    lines=6,
                    value="distant galaxy with swirling spiral arms\nstar system with multiple planets\nplanet surface with mountains\nclose-up of alien vegetation"
                )
                
                zoom_factors_input = gr.Textbox(
                    label="ç¼©æ”¾å› å­ (2çš„å¹‚åºåˆ—ï¼Œé€—å·åˆ†éš”)",
                    placeholder="ä¾‹å¦‚ï¼š1, 2, 4, 8",
                    value="1, 2, 4, 8"
                )
                
                generate_btn = gr.Button("ğŸš€ ç”Ÿæˆç¼©æ”¾æ ˆ", variant="primary", size="lg")
                
                status_text = gr.Textbox(
                    label="çŠ¶æ€",
                    value="å‡†å¤‡å°±ç»ª",
                    interactive=False,
                    elem_classes=["status-text"]
                )
                
                # ç¤ºä¾‹æŒ‰é’®
                gr.Markdown("### ğŸ¯ å¿«é€Ÿç¤ºä¾‹")
                examples = get_example_inputs()
                
                with gr.Row():
                    cosmic_btn = gr.Button("ğŸŒŒ å®‡å®™ç¼©æ”¾", size="sm")
                    nature_btn = gr.Button("ğŸŒ³ è‡ªç„¶ç¼©æ”¾", size="sm")
                    ocean_btn = gr.Button("ğŸŒŠ æµ·æ´‹ç¼©æ”¾", size="sm")
            
            # å³ä¾§ï¼šæ˜¾ç¤ºé¢æ¿
            with gr.Column(scale=2):
                gr.Markdown("## ğŸ–¼ï¸ å›¾åƒæ˜¾ç¤º")
                
                # ä¸»å›¾åƒæ˜¾ç¤º
                main_image = gr.Image(
                    label="å½“å‰å°ºåº¦å›¾åƒ",
                    type="pil",
                    height=400
                )
                
                # ç¼©æ”¾çº§åˆ«æ§åˆ¶
                scale_slider = gr.Slider(
                    minimum=0,
                    maximum=3,
                    value=0,
                    step=1,
                    label="ç¼©æ”¾çº§åˆ«",
                    visible=False
                )
                
                scale_info = gr.Textbox(
                    label="å°ºåº¦ä¿¡æ¯",
                    value="",
                    interactive=False
                )
                
                # åŠ¨ç”»æ§åˆ¶
                gr.Markdown("### ğŸ¬ ç¼©æ”¾åŠ¨ç”»")
                with gr.Row():
                    animation_btn = gr.Button("â–¶ï¸ åˆ›å»ºç¼©æ”¾åŠ¨ç”»", variant="secondary")
                
                animation_output = gr.File(
                    label="åŠ¨ç”»æ–‡ä»¶",
                    visible=False
                )
                
                animation_status = gr.Textbox(
                    label="åŠ¨ç”»çŠ¶æ€",
                    value="",
                    interactive=False
                )
        
        # äº‹ä»¶ç»‘å®š
        
        # ç”Ÿæˆç¼©æ”¾æ ˆ
        generate_btn.click(
            fn=generate_zoom_stack,
            inputs=[prompts_input, zoom_factors_input],
            outputs=[status_text, main_image, scale_slider]
        )
        
        # æ»‘å—å˜åŒ–æ—¶é‡æ–°æ¸²æŸ“
        scale_slider.change(
            fn=render_scale_image,
            inputs=[scale_slider],
            outputs=[main_image, scale_info]
        )
        
        # åˆ›å»ºåŠ¨ç”»
        animation_btn.click(
            fn=create_zoom_animation,
            outputs=[animation_output, animation_status]
        ).then(
            lambda: gr.update(visible=True),
            outputs=[animation_output]
        )
        
        # ç¤ºä¾‹æŒ‰é’®äº‹ä»¶
        cosmic_btn.click(
            lambda: (examples["cosmic"]["prompts"], examples["cosmic"]["zoom_factors"]),
            outputs=[prompts_input, zoom_factors_input]
        )
        
        nature_btn.click(
            lambda: (examples["nature"]["prompts"], examples["nature"]["zoom_factors"]),
            outputs=[prompts_input, zoom_factors_input]
        )
        
        ocean_btn.click(
            lambda: (examples["ocean"]["prompts"], examples["ocean"]["zoom_factors"]),
            outputs=[prompts_input, zoom_factors_input]
        )
        
        # åº•éƒ¨è¯´æ˜
        gr.HTML("""
        <div style="margin-top: 2rem; padding: 1rem; background-color: #f0f0f0; border-radius: 8px;">
            <h3>ğŸ“– ä½¿ç”¨è¯´æ˜</h3>
            <ul>
                <li><strong>æ–‡æœ¬æç¤º</strong>ï¼šè¾“å…¥æè¿°ä¸åŒå°ºåº¦çš„æ–‡æœ¬ï¼Œä»æœ€å¤§å°ºåº¦åˆ°æœ€å°å°ºåº¦</li>
                <li><strong>ç¼©æ”¾å› å­</strong>ï¼šå¿…é¡»æ˜¯2çš„å¹‚åºåˆ—ï¼Œå¦‚ 1, 2, 4, 8</li>
                <li><strong>ç”Ÿæˆ</strong>ï¼šç‚¹å‡»ç”ŸæˆæŒ‰é’®åˆ›å»ºç¼©æ”¾æ ˆï¼ˆéœ€è¦å‡ åˆ†é’Ÿï¼‰</li>
                <li><strong>æµè§ˆ</strong>ï¼šä½¿ç”¨æ»‘å—å®æ—¶æŸ¥çœ‹ä¸åŒç¼©æ”¾çº§åˆ«çš„å›¾åƒ</li>
                <li><strong>åŠ¨ç”»</strong>ï¼šåˆ›å»ºä»ç²—åˆ°ç»†çš„ç¼©æ”¾åŠ¨ç”»GIFæ–‡ä»¶</li>
            </ul>
            <p><strong>æ³¨æ„</strong>ï¼šé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸</p>
        </div>
        """)
    
    return demo

# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    print("=== Generative Powers of Ten - Gradio Interface ===")
    print(f"è®¾å¤‡: {device}")
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åŠ è½½æ¨¡å‹
    try:
        print("æ­£åœ¨æ£€æŸ¥æ¨¡å‹...")
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡å‹é¢„åŠ è½½é€»è¾‘
        print("âœ… å‡†å¤‡å°±ç»ª")
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹æ£€æŸ¥å¤±è´¥: {e}")
        print("   é¦–æ¬¡è¿è¡Œæ—¶å°†è‡ªåŠ¨ä¸‹è½½æ¨¡å‹")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_gradio_interface()
    
    # å¯åŠ¨æœåŠ¡å™¨
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,       # ç«¯å£å·
        share=False,            # ä¸åˆ›å»ºå…¬å…±é“¾æ¥ï¼ˆå¯è®¾ä¸ºTrueåˆ›å»ºä¸´æ—¶å…¬å…±URLï¼‰
        debug=True,             # è°ƒè¯•æ¨¡å¼
        show_error=True         # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    )

if __name__ == "__main__":
    main() 