import torch
import numpy as np
import warnings
warnings.filterwarnings("ignore")

# è®¾å¤‡é…ç½®
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# ==================== ç¼©æ”¾æ ˆæ•°æ®ç»“æ„ ====================

class ZoomStack:
    """ç¼©æ”¾æ ˆæ•°æ®ç»“æ„
    
    æ ¹æ® 'Generative Powers of Ten' è®ºæ–‡å®ç°çš„ç¼©æ”¾æ ˆï¼š
    ä¸€ä¸ªå¼ é‡åˆ—è¡¨ L = [L_0, L_1, ..., L_{N-1}]ï¼Œå…¶ä¸­æ¯ä¸ª L_i æ˜¯ HxWx3 å›¾åƒå¼ é‡
    """
    
    def __init__(self, zoom_factors, H=512, W=512, device="cuda"):
        """åˆå§‹åŒ–ç¼©æ”¾æ ˆ
        
        Args:
            zoom_factors: ç¼©æ”¾å› å­åˆ—è¡¨ï¼Œä¾‹å¦‚ [1, 2, 4, 8]
            H: å›¾åƒé«˜åº¦
            W: å›¾åƒå®½åº¦ 
            device: è®¾å¤‡ç±»å‹
        """
        self.zoom_factors = zoom_factors
        self.N = len(zoom_factors)
        self.H = H
        self.W = W
        self.device = device
        
        # éªŒè¯ç¼©æ”¾å› å­æ˜¯2çš„å¹‚
        for i, p in enumerate(zoom_factors):
            if i == 0:
                assert p == 1, "ç¬¬ä¸€ä¸ªç¼©æ”¾å› å­å¿…é¡»æ˜¯1"
            else:
                assert p == 2 * zoom_factors[i-1], f"ç¼©æ”¾å› å­å¿…é¡»æ˜¯2çš„å¹‚åºåˆ—ï¼Œä½†å¾—åˆ° {p} åœ¨ä½ç½® {i}"
        
        # åˆå§‹åŒ–å±‚ï¼šL = [L_0, L_1, ..., L_{N-1}]
        # æ¯ä¸ª L_i æ˜¯ HxWx3 å¼ é‡ï¼Œä»é«˜æ–¯å™ªå£°åˆå§‹åŒ–
        self.layers = self._initialize_layers()
        
    def _initialize_layers(self):
        """ä»é«˜æ–¯å™ªå£°åˆå§‹åŒ–æ‰€æœ‰å±‚"""
        layers = []
        for i, p in enumerate(self.zoom_factors):
            # æ¯å±‚éƒ½æ˜¯å…¨åˆ†è¾¨ç‡ HxWx3ï¼Œä½†ä»£è¡¨ä¸åŒçš„ç¼©æ”¾çº§åˆ«
            layer = torch.randn(self.H, self.W, 3, device=self.device, dtype=torch.float32)
            # æ ‡å‡†åŒ–åˆ° [-1, 1] èŒƒå›´
            layer = layer * 0.1  # å‡å°åˆå§‹å™ªå£°å¹…åº¦
            layers.append(layer)
        return layers
    
    def get_layer(self, i):
        """è·å–ç¬¬ i å±‚"""
        assert 0 <= i < self.N, f"å±‚ç´¢å¼• {i} è¶…å‡ºèŒƒå›´ [0, {self.N-1}]"
        return self.layers[i]
    
    def set_layer(self, i, layer):
        """è®¾ç½®ç¬¬ i å±‚"""
        assert 0 <= i < self.N, f"å±‚ç´¢å¼• {i} è¶…å‡ºèŒƒå›´ [0, {self.N-1}]"
        assert layer.shape == (self.H, self.W, 3), f"å±‚å½¢çŠ¶å¿…é¡»æ˜¯ ({self.H}, {self.W}, 3)ï¼Œä½†å¾—åˆ° {layer.shape}"
        self.layers[i] = layer.to(self.device)
    
    def get_zoom_factor(self, i):
        """è·å–ç¬¬ i å±‚çš„ç¼©æ”¾å› å­"""
        assert 0 <= i < self.N, f"å±‚ç´¢å¼• {i} è¶…å‡ºèŒƒå›´ [0, {self.N-1}]"
        return self.zoom_factors[i]
    
    def get_all_layers(self):
        """è·å–æ‰€æœ‰å±‚çš„å‰¯æœ¬"""
        return [layer.clone() for layer in self.layers]
    
    def update_layers(self, new_layers):
        """æ›´æ–°æ‰€æœ‰å±‚"""
        assert len(new_layers) == self.N, f"æ–°å±‚æ•°é‡ {len(new_layers)} ä¸åŒ¹é…ç¼©æ”¾æ ˆå¤§å° {self.N}"
        for i, layer in enumerate(new_layers):
            self.set_layer(i, layer)
    
    def print_info(self):
        """æ‰“å°ç¼©æ”¾æ ˆä¿¡æ¯"""
        print(f"\n=== ç¼©æ”¾æ ˆä¿¡æ¯ ===")
        print(f"å±‚æ•°: {self.N}")
        print(f"å›¾åƒå°ºå¯¸: {self.H}x{self.W}")
        print(f"è®¾å¤‡: {self.device}")
        print(f"ç¼©æ”¾å› å­: {self.zoom_factors}")
        for i, p in enumerate(self.zoom_factors):
            layer = self.layers[i]
            print(f"  L_{i}: ç¼©æ”¾å› å­={p}, å½¢çŠ¶={layer.shape}, æ•°æ®èŒƒå›´=[{layer.min():.3f}, {layer.max():.3f}]")

def create_zoom_stack(zoom_factors, H=512, W=512, device="cuda"):
    """åˆ›å»ºç¼©æ”¾æ ˆçš„ä¾¿æ·å‡½æ•°"""
    return ZoomStack(zoom_factors, H, W, device)

def generate_zoom_factors(N):
    """ç”Ÿæˆ N ä¸ªç¼©æ”¾å› å­ï¼š[1, 2, 4, ..., 2^{N-1}]"""
    return [2**i for i in range(N)]

# ==================== æ¸²æŸ“å‡½æ•° (Pi_image, Pi_noise) ====================

def Pi_image(zoom_stack, i):
    """
    ä»ç¼©æ”¾æ ˆæ¸²æŸ“å›¾åƒï¼ˆç®—æ³• 1ï¼‰
    
    æ ¹æ® 'Generative Powers of Ten' è®ºæ–‡ç®—æ³• 1 å®ç°
    
    Args:
        zoom_stack: ZoomStack å¯¹è±¡ï¼ŒåŒ…å«å¤šå±‚å›¾åƒ
        i: å½“å‰å±‚çš„ç´¢å¼•
    
    Returns:
        torch.Tensor: æ¸²æŸ“çš„å›¾åƒå¼ é‡ï¼Œå½¢çŠ¶ä¸º (H, W, 3)
    """
    # è·å–å½“å‰å±‚ä½œä¸ºåŸºç¡€
    rendered = zoom_stack.get_layer(i).clone()
    H, W = rendered.shape[:2]
    
    # å½“å‰å±‚çš„ç¼©æ”¾å› å­
    p_i = zoom_stack.get_zoom_factor(i)
    
    # å¯¹äºæ‰€æœ‰æ›´é«˜å±‚ (j > i)ï¼Œä¸‹é‡‡æ ·å¹¶èåˆ
    for j in range(i + 1, zoom_stack.N):
        # è·å–ç¬¬jå±‚å’Œå…¶ç¼©æ”¾å› å­
        layer_j = zoom_stack.get_layer(j)
        p_j = zoom_stack.get_zoom_factor(j)
        
        # è®¡ç®—ä¸­å¿ƒè£å‰ªåŒºåŸŸçš„å°ºå¯¸
        # æ ¹æ®ç¼©æ”¾å› å­ï¼Œç¬¬iå±‚çœ‹åˆ°çš„ç¬¬jå±‚çš„æœ‰æ•ˆåŒºåŸŸ
        crop_h = H // p_j
        crop_w = W // p_j
        
        # ä¸­å¿ƒè£å‰ªç¬¬jå±‚
        start_h = (H - crop_h) // 2
        start_w = (W - crop_w) // 2
        end_h = start_h + crop_h
        end_w = start_w + crop_w
        
        cropped_j = layer_j[start_h:end_h, start_w:end_w, :]
        
        # å°†è£å‰ªåçš„åŒºåŸŸä¸Šé‡‡æ ·åˆ°å®Œæ•´åˆ†è¾¨ç‡ (H, W)
        # è½¬æ¢ä¸º (C, H, W) æ ¼å¼ç”¨äº interpolate
        cropped_j_chw = cropped_j.permute(2, 0, 1).unsqueeze(0)  # (1, 3, crop_h, crop_w)
        
        # åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·
        upsampled_j = torch.nn.functional.interpolate(
            cropped_j_chw, 
            size=(H, W), 
            mode='bilinear', 
            align_corners=False
        )
        
        # è½¬æ¢å› (H, W, C) æ ¼å¼
        upsampled_j = upsampled_j.squeeze(0).permute(1, 2, 0)
        
        # åˆ›å»ºèåˆæ©ç ï¼ˆä¸­å¿ƒåŒºåŸŸï¼‰
        mask = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
        mask_h_start = (H - crop_h * p_j) // 2
        mask_w_start = (W - crop_w * p_j) // 2
        mask_h_end = mask_h_start + crop_h * p_j
        mask_w_end = mask_w_start + crop_w * p_j
        
        mask[mask_h_start:mask_h_end, mask_w_start:mask_w_end, :] = 1.0
        
        # ä½¿ç”¨æ©ç èåˆ
        rendered = rendered * (1 - mask) + upsampled_j * mask
    
    return rendered


def Pi_noise(zoom_stack, i):
    """
    ä»ç¼©æ”¾æ ˆæ¸²æŸ“å™ªå£°ï¼ˆç®—æ³• 1ï¼‰
    
    æ ¹æ® 'Generative Powers of Ten' è®ºæ–‡ç®—æ³• 1 å®ç°å™ªå£°æ¸²æŸ“
    
    Args:
        zoom_stack: ZoomStack å¯¹è±¡ï¼ŒåŒ…å«å¤šå±‚å›¾åƒ
        i: å½“å‰å±‚çš„ç´¢å¼•
    
    Returns:
        torch.Tensor: æ¸²æŸ“çš„å™ªå£°å¼ é‡ï¼Œå½¢çŠ¶ä¸º (H, W, 3)ï¼Œæ»¡è¶³ N(0,I)
    """
    # è·å–å›¾åƒå°ºå¯¸
    H, W = zoom_stack.H, zoom_stack.W
    
    # åˆå§‹åŒ–å™ªå£°ä¸ºé›¶
    rendered_noise = torch.zeros((H, W, 3), device=zoom_stack.device, dtype=torch.float32)
    
    # å½“å‰å±‚çš„ç¼©æ”¾å› å­
    p_i = zoom_stack.get_zoom_factor(i)
    
    # å™ªå£°æ–¹å·®ç´¯ç§¯å™¨
    total_variance = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
    
    # å¯¹äºæ‰€æœ‰å±‚ j >= i
    for j in range(i, zoom_stack.N):
        p_j = zoom_stack.get_zoom_factor(j)
        
        # è®¡ç®—å™ªå£°ç¼©æ”¾å› å­
        noise_scale = p_j / p_i
        
        # è®¡ç®—è¯¥å±‚å¯¹åº”çš„å™ªå£°åŒºåŸŸ
        if j == i:
            # å½“å‰å±‚ï¼šå…¨åˆ†è¾¨ç‡å™ªå£°
            layer_noise = torch.randn((H, W, 3), device=zoom_stack.device, dtype=torch.float32)
            layer_noise *= noise_scale
            mask = torch.ones((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
        else:
            # æ›´é«˜å±‚ï¼šä¸­å¿ƒè£å‰ªåŒºåŸŸçš„å™ªå£°
            crop_h = H // p_j
            crop_w = W // p_j
            
            # ç”Ÿæˆè£å‰ªå°ºå¯¸çš„å™ªå£°
            cropped_noise = torch.randn((crop_h, crop_w, 3), device=zoom_stack.device, dtype=torch.float32)
            cropped_noise *= noise_scale
            
            # ä¸Šé‡‡æ ·åˆ°å®Œæ•´åˆ†è¾¨ç‡
            cropped_noise_chw = cropped_noise.permute(2, 0, 1).unsqueeze(0)
            upsampled_noise = torch.nn.functional.interpolate(
                cropped_noise_chw,
                size=(H, W),
                mode='bilinear',
                align_corners=False
            )
            layer_noise = upsampled_noise.squeeze(0).permute(1, 2, 0)
            
            # åˆ›å»ºä¸­å¿ƒåŒºåŸŸæ©ç 
            mask = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
            mask_h_start = (H - crop_h * p_j) // 2
            mask_w_start = (W - crop_w * p_j) // 2
            mask_h_end = mask_h_start + crop_h * p_j
            mask_w_end = mask_w_start + crop_w * p_j
            
            mask[mask_h_start:mask_h_end, mask_w_start:mask_w_end, :] = 1.0
            
            # åªåœ¨æ©ç åŒºåŸŸåº”ç”¨å™ªå£°
            layer_noise = layer_noise * mask
        
        # ç´¯ç§¯å™ªå£°å’Œæ–¹å·®
        rendered_noise += layer_noise
        total_variance += mask * (noise_scale ** 2)
    
    # å½’ä¸€åŒ–ä»¥ç¡®ä¿ N(0,I) åˆ†å¸ƒ
    # é¿å…é™¤é›¶
    std_dev = torch.sqrt(total_variance + 1e-8)
    rendered_noise = rendered_noise / std_dev
    
    return rendered_noise

# ==================== æµ‹è¯•å‡½æ•° ====================

def test_rendering_functions():
    """æµ‹è¯•æ¸²æŸ“å‡½æ•° Pi_image å’Œ Pi_noise"""
    print("\n=== æµ‹è¯•æ¸²æŸ“å‡½æ•° (Pi_image, Pi_noise) ===")
    
    # åˆ›å»ºæµ‹è¯•ç¼©æ”¾æ ˆ
    zoom_factors = [1, 2, 4, 8]
    zoom_stack = create_zoom_stack(zoom_factors, H=256, W=256, device=device)
    
    print(f"åˆ›å»ºæµ‹è¯•ç¼©æ”¾æ ˆ: å±‚æ•°={zoom_stack.N}, ç¼©æ”¾å› å­={zoom_factors}")
    
    # å¡«å……ä¸€äº›æµ‹è¯•æ•°æ®åˆ°å„å±‚
    for i in range(zoom_stack.N):
        # ä¸ºæ¯å±‚åˆ›å»ºä¸åŒçš„æ¨¡å¼ï¼Œä¾¿äºå¯è§†åŒ–
        test_data = torch.zeros((256, 256, 3), device=device, dtype=torch.float32)
        # åœ¨ä¸åŒä½ç½®åˆ›å»ºä¸åŒé¢œè‰²çš„æ–¹å—
        size = 64 // zoom_factors[i]
        start = 128 - size // 2
        end = start + size
        test_data[start:end, start:end, i % 3] = 0.5  # ä¸åŒé€šé“ä¸åŒé¢œè‰²
        zoom_stack.set_layer(i, test_data)
    
    print("\n--- æµ‹è¯• Pi_image å‡½æ•° ---")
    
    # æµ‹è¯•æ¯ä¸€å±‚çš„å›¾åƒæ¸²æŸ“
    for i in range(zoom_stack.N):
        try:
            rendered_img = Pi_image(zoom_stack, i)
            print(f"Pi_image(L, {i}): æˆåŠŸ")
            print(f"  - è¾“å‡ºå½¢çŠ¶: {rendered_img.shape}")
            print(f"  - æ•°æ®èŒƒå›´: [{rendered_img.min():.3f}, {rendered_img.max():.3f}]")
            print(f"  - è®¾å¤‡: {rendered_img.device}")
            
            # éªŒè¯å½¢çŠ¶
            assert rendered_img.shape == (256, 256, 3), f"å½¢çŠ¶é”™è¯¯: {rendered_img.shape}"
            
        except Exception as e:
            print(f"Pi_image(L, {i}): å¤±è´¥ - {e}")
            return False
    
    print("\n--- æµ‹è¯• Pi_noise å‡½æ•° ---")
    
    # æµ‹è¯•æ¯ä¸€å±‚çš„å™ªå£°æ¸²æŸ“
    for i in range(zoom_stack.N):
        try:
            rendered_noise = Pi_noise(zoom_stack, i)
            print(f"Pi_noise(L, {i}): æˆåŠŸ")
            print(f"  - è¾“å‡ºå½¢çŠ¶: {rendered_noise.shape}")
            print(f"  - æ•°æ®èŒƒå›´: [{rendered_noise.min():.3f}, {rendered_noise.max():.3f}]")
            print(f"  - å‡å€¼: {rendered_noise.mean():.3f} (åº”æ¥è¿‘0)")
            print(f"  - æ ‡å‡†å·®: {rendered_noise.std():.3f} (åº”æ¥è¿‘1)")
            print(f"  - è®¾å¤‡: {rendered_noise.device}")
            
            # éªŒè¯å½¢çŠ¶
            assert rendered_noise.shape == (256, 256, 3), f"å½¢çŠ¶é”™è¯¯: {rendered_noise.shape}"
            
            # éªŒè¯å™ªå£°åˆ†å¸ƒï¼ˆå…è®¸ä¸€å®šè¯¯å·®ï¼‰
            mean_val = rendered_noise.mean().item()
            std_val = rendered_noise.std().item()
            if abs(mean_val) > 0.1:
                print(f"    è­¦å‘Š: å‡å€¼åç¦»0è¾ƒè¿œ: {mean_val}")
            if abs(std_val - 1.0) > 0.2:
                print(f"    è­¦å‘Š: æ ‡å‡†å·®åç¦»1è¾ƒè¿œ: {std_val}")
            
        except Exception as e:
            print(f"Pi_noise(L, {i}): å¤±è´¥ - {e}")
            return False
    
    print("\nâœ… æ‰€æœ‰æ¸²æŸ“å‡½æ•°æµ‹è¯•é€šè¿‡!")
    return True

def test_visual_patterns():
    """æµ‹è¯•å¯è§†åŒ–æ¨¡å¼"""
    print("\n=== æµ‹è¯•å¯è§†åŒ–æ¨¡å¼ ===")
    
    zoom_factors = [1, 2, 4]
    zoom_stack = create_zoom_stack(zoom_factors, H=128, W=128, device=device)
    
    # åˆ›å»ºä¸åŒçš„è§†è§‰æ¨¡å¼
    # Layer 0 (1x): æ•´ä¸ªå›¾åƒä¸ºè“è‰²
    layer_0 = torch.zeros((128, 128, 3), device=device, dtype=torch.float32)
    layer_0[:, :, 2] = 0.8  # è“è‰²
    zoom_stack.set_layer(0, layer_0)
    
    # Layer 1 (2x): ä¸­å¿ƒåŒºåŸŸä¸ºç»¿è‰²
    layer_1 = torch.zeros((128, 128, 3), device=device, dtype=torch.float32)
    layer_1[32:96, 32:96, 1] = 0.8  # ç»¿è‰²
    zoom_stack.set_layer(1, layer_1)
    
    # Layer 2 (4x): ä¸­å¿ƒå°åŒºåŸŸä¸ºçº¢è‰²
    layer_2 = torch.zeros((128, 128, 3), device=device, dtype=torch.float32)
    layer_2[48:80, 48:80, 0] = 0.8  # çº¢è‰²
    zoom_stack.set_layer(2, layer_2)
    
    print("åˆ›å»ºäº†ä¸‰å±‚æµ‹è¯•å›¾æ¡ˆ:")
    print("  Layer 0: å…¨è“è‰²èƒŒæ™¯")
    print("  Layer 1: ä¸­å¿ƒç»¿è‰²åŒºåŸŸ")
    print("  Layer 2: ä¸­å¿ƒå°çº¢è‰²åŒºåŸŸ")
    
    # æµ‹è¯•æ¸²æŸ“
    for i in range(3):
        rendered = Pi_image(zoom_stack, i)
        print(f"\næ¸²æŸ“ç¬¬{i}å±‚:")
        print(f"  å‡å€¼: R={rendered[:,:,0].mean():.3f}, G={rendered[:,:,1].mean():.3f}, B={rendered[:,:,2].mean():.3f}")
        print(f"  æœ€å¤§å€¼: R={rendered[:,:,0].max():.3f}, G={rendered[:,:,1].max():.3f}, B={rendered[:,:,2].max():.3f}")


# ==================== å¤šåˆ†è¾¨ç‡èåˆå’Œè”åˆé‡‡æ ·ï¼ˆæ— ä¾èµ–ç‰ˆæœ¬ï¼‰====================

def multi_resolution_blending_simple(predictions, zoom_stack):
    """ç®€åŒ–ç‰ˆå¤šåˆ†è¾¨ç‡èåˆ"""
    new_zoom_stack = create_zoom_stack(
        zoom_stack.zoom_factors, 
        zoom_stack.H, 
        zoom_stack.W, 
        zoom_stack.device
    )
    
    for i in range(zoom_stack.N):
        # ç®€å•çš„åŠ æƒå¹³å‡èåˆ
        blended = predictions[i].clone()
        
        # ä»æ›´é«˜å±‚èåˆä¿¡æ¯
        for j in range(i + 1, zoom_stack.N):
            p_j = zoom_stack.get_zoom_factor(j)
            pred_j = predictions[j]
            
            # ä¸­å¿ƒè£å‰ª
            crop_size = zoom_stack.H // p_j
            start = (zoom_stack.H - crop_size) // 2
            end = start + crop_size
            cropped = pred_j[start:end, start:end, :]
            
            # ä¸Šé‡‡æ ·
            cropped_chw = cropped.permute(2, 0, 1).unsqueeze(0)
            upsampled = torch.nn.functional.interpolate(
                cropped_chw, 
                size=(zoom_stack.H, zoom_stack.W), 
                mode='bilinear', 
                align_corners=False
            )
            upsampled = upsampled.squeeze(0).permute(1, 2, 0)
            
            # èåˆï¼ˆç®€å•å¹³å‡ï¼‰
            weight = 0.5 / (p_j / zoom_stack.get_zoom_factor(i))
            blended = blended * (1 - weight) + upsampled * weight
        
        new_zoom_stack.set_layer(i, blended)
    
    return new_zoom_stack


def joint_multi_scale_sampling_simple(prompts, zoom_factors, T=20, H=128, W=128):
    """ç®€åŒ–ç‰ˆè”åˆå¤šå°ºåº¦é‡‡æ ·"""
    print(f"\n=== ç®€åŒ–è”åˆå¤šå°ºåº¦é‡‡æ · ===")
    print(f"æç¤º: {prompts}")
    print(f"ç¼©æ”¾å› å­: {zoom_factors}")
    print(f"æ­¥æ•°: {T}")
    
    N = len(prompts)
    zoom_stack = create_zoom_stack(zoom_factors, H, W, device)
    
    # ç®€åŒ–çš„æ‰©æ•£å¾ªç¯
    for t in range(T, 0, -1):
        progress = (T - t + 1) / T
        print(f"æ­¥éª¤ {T-t+1}/{T} (è¿›åº¦: {progress:.1%})")
        
        # 1. æ¸²æŸ“å½“å‰çŠ¶æ€
        z_t_list = []
        for i in range(N):
            img_rendered = Pi_image(zoom_stack, i)
            noise_rendered = Pi_noise(zoom_stack, i)
            
            # ç®€åŒ–çš„å™ªå£°è°ƒåº¦
            noise_level = t / T
            z_t = img_rendered + noise_level * noise_rendered * 0.5
            z_t_list.append(z_t)
        
        # 2. æ¨¡æ‹Ÿæ¨¡å‹é¢„æµ‹ï¼ˆé€æ­¥å»å™ªï¼‰
        x_hat_list = []
        for i in range(N):
            # æ¸è¿›å¼å»å™ª
            denoising_strength = progress
            
            # æ·»åŠ ä¸€äº›åŸºäºæç¤ºçš„"å†…å®¹"
            content_pattern = torch.sin(torch.linspace(0, 2*torch.pi*i, H*W, device=device)).reshape(H, W, 1)
            content_pattern = content_pattern.repeat(1, 1, 3) * 0.3
            
            # æ··åˆå»å™ªå’Œå†…å®¹
            x_hat = (z_t_list[i] * (1 - denoising_strength) + 
                    content_pattern * denoising_strength)
            
            x_hat_list.append(x_hat)
        
        # 3. å¤šåˆ†è¾¨ç‡èåˆ
        zoom_stack = multi_resolution_blending_simple(x_hat_list, zoom_stack)
    
    print("âœ… ç®€åŒ–é‡‡æ ·å®Œæˆ!")
    return zoom_stack


def test_joint_sampling():
    """æµ‹è¯•è”åˆé‡‡æ ·ç®—æ³•"""
    print("\n=== æµ‹è¯•è”åˆå¤šå°ºåº¦é‡‡æ · ===")
    
    prompts = ["cosmic view", "star field", "planet", "surface details"]
    zoom_factors = [1, 2, 4, 8]
    
    try:
        result = joint_multi_scale_sampling_simple(
            prompts=prompts,
            zoom_factors=zoom_factors,
            T=5,  # å¿«é€Ÿæµ‹è¯•
            H=64, W=64
        )
        
        print("\né‡‡æ ·ç»“æœ:")
        result.print_info()
        
        # éªŒè¯ç»“æœ
        for i in range(len(zoom_factors)):
            layer = result.get_layer(i)
            print(f"å±‚ {i}: èŒƒå›´=[{layer.min():.3f}, {layer.max():.3f}]")
        
        return True
        
    except Exception as e:
        print(f"é‡‡æ ·æµ‹è¯•å¤±è´¥: {e}")
        return False

# ==================== DDPM æ›´æ–°æ­¥éª¤ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰====================

def get_noise_schedule_simple(num_timesteps=1000, beta_start=0.00085, beta_end=0.012):
    """è·å–ç®€åŒ–ç‰ˆå™ªå£°è°ƒåº¦å‚æ•°"""
    betas = torch.linspace(beta_start, beta_end, num_timesteps, dtype=torch.float32)
    alphas = 1.0 - betas
    alphas_cumprod = torch.cumprod(alphas, dim=0)
    
    return {
        'betas': betas,
        'alphas': alphas, 
        'alphas_cumprod': alphas_cumprod,
        'sqrt_alphas_cumprod': torch.sqrt(alphas_cumprod),
        'sqrt_one_minus_alphas_cumprod': torch.sqrt(1.0 - alphas_cumprod)
    }

# ç®€åŒ–ç‰ˆå™ªå£°è°ƒåº¦
noise_schedule_simple = get_noise_schedule_simple()


def ddpm_update_simple(z_t, x_hat, epsilon, t, num_timesteps=1000):
    """ç®€åŒ–ç‰ˆDDPMæ›´æ–°æ­¥éª¤"""
    # ç¡®ä¿tåœ¨æœ‰æ•ˆèŒƒå›´å†…
    t = max(0, min(t, num_timesteps - 1))
    
    # è·å–è°ƒåº¦å‚æ•°
    alpha_t = noise_schedule_simple['alphas'][t]
    alpha_bar_t = noise_schedule_simple['alphas_cumprod'][t]
    beta_t = noise_schedule_simple['betas'][t]
    
    sqrt_alpha_t = torch.sqrt(alpha_t)
    sqrt_one_minus_alpha_bar_t = noise_schedule_simple['sqrt_one_minus_alphas_cumprod'][t]
    
    # è®¡ç®—é¢„æµ‹å‡å€¼
    coeff1 = 1.0 / sqrt_alpha_t
    coeff2 = beta_t / sqrt_one_minus_alpha_bar_t
    
    pred_mean = coeff1 * (z_t - coeff2 * epsilon)
    
    # å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œä¸æ·»åŠ å™ªå£°
    if t == 0:
        return pred_mean
    else:
        # æ·»åŠ å™ªå£°
        sigma_t = torch.sqrt(beta_t)
        noise = torch.randn_like(z_t)
        return pred_mean + sigma_t * noise


def test_ddpm_update_simple():
    """æµ‹è¯•ç®€åŒ–ç‰ˆDDPMæ›´æ–°æ­¥éª¤"""
    print("\n=== æµ‹è¯•DDPMæ›´æ–°æ­¥éª¤ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    H, W = 32, 32
    z_t = torch.randn((H, W, 3), device=device, dtype=torch.float32)
    x_hat = torch.randn((H, W, 3), device=device, dtype=torch.float32) * 0.5
    epsilon = torch.randn((H, W, 3), device=device, dtype=torch.float32)
    
    print(f"è¾“å…¥å½¢çŠ¶: z_t={z_t.shape}, x_hat={x_hat.shape}, epsilon={epsilon.shape}")
    
    # æµ‹è¯•å‡ ä¸ªå…³é”®æ—¶é—´æ­¥
    for t in [999, 500, 100, 10, 0]:
        try:
            z_t_prev = ddpm_update_simple(z_t, x_hat, epsilon, t)
            print(f"t={t}: æ›´æ–°æˆåŠŸ, è¾“å‡ºèŒƒå›´=[{z_t_prev.min():.3f}, {z_t_prev.max():.3f}]")
            
            # éªŒè¯è¾“å‡ºå½¢çŠ¶
            assert z_t_prev.shape == z_t.shape, f"å½¢çŠ¶ä¸åŒ¹é…"
            
        except Exception as e:
            print(f"t={t}: æ›´æ–°å¤±è´¥ - {e}")
            return False
    
    print("âœ… DDPMæ›´æ–°æ­¥éª¤æµ‹è¯•æˆåŠŸ!")
    return True

# ==================== åŸºäºç…§ç‰‡çš„ç¼©æ”¾ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰====================

def photo_based_optimization_simple(x_hat_list, input_image, zoom_stack, num_steps=3, lr=0.05):
    """ç®€åŒ–ç‰ˆåŸºäºç…§ç‰‡çš„ä¼˜åŒ–"""
    optimized_x_hat = []
    
    for i, x_hat in enumerate(x_hat_list):
        x_hat_opt = x_hat.clone().detach().requires_grad_(True)
        optimizer = torch.optim.Adam([x_hat_opt], lr=lr)
        
        for step in range(num_steps):
            optimizer.zero_grad()
            
            # è®¡ç®—ä¸è¾“å…¥å›¾åƒçš„L2æŸå¤±
            p_i = zoom_stack.get_zoom_factor(i)
            H, W = zoom_stack.H, zoom_stack.W
            
            # ä¸­å¿ƒè£å‰ª
            crop_h = H // p_i
            crop_w = W // p_i
            start_h = (H - crop_h) // 2
            start_w = (W - crop_w) // 2
            end_h = start_h + crop_h
            end_w = start_w + crop_w
            
            cropped_x_hat = x_hat_opt[start_h:end_h, start_w:end_w, :]
            input_crop = input_image[start_h:end_h, start_w:end_w, :]
            
            # L2æŸå¤±
            loss = torch.nn.functional.mse_loss(cropped_x_hat, input_crop)
            loss.backward()
            optimizer.step()
        
        optimized_x_hat.append(x_hat_opt.detach())
    
    return optimized_x_hat


def joint_sampling_with_photo_simple(prompts, zoom_factors, input_image, T=10, H=64, W=64):
    """åŸºäºç…§ç‰‡çš„ç®€åŒ–è”åˆé‡‡æ ·"""
    print(f"\n=== åŸºäºç…§ç‰‡çš„ç®€åŒ–è”åˆé‡‡æ · ===")
    print(f"è¾“å…¥å›¾åƒå½¢çŠ¶: {input_image.shape}")
    
    N = len(prompts)
    zoom_stack = create_zoom_stack(zoom_factors, H, W, device)
    
    # ä½¿ç”¨è¾“å…¥å›¾åƒåˆå§‹åŒ–
    for i in range(N):
        p_i = zoom_factors[i]
        noise_level = 0.03 * p_i
        init_layer = input_image + torch.randn_like(input_image) * noise_level
        zoom_stack.set_layer(i, init_layer)
    
    for t in range(T, 0, -1):
        progress = (T - t + 1) / T
        print(f"æ­¥éª¤ {T-t+1}/{T} (è¿›åº¦: {progress:.1%})")
        
        # æ¸²æŸ“å’Œé¢„æµ‹
        x_hat_list = []
        for i in range(N):
            img_rendered = Pi_image(zoom_stack, i)
            noise_rendered = Pi_noise(zoom_stack, i)
            
            noise_level = t / T
            z_t = img_rendered + noise_level * noise_rendered * 0.2
            
            denoising_strength = progress
            x_hat = (z_t * (1 - denoising_strength) + 
                    input_image * denoising_strength * 0.8)
            
            x_hat_list.append(x_hat)
        
        # ç…§ç‰‡ä¼˜åŒ–ï¼ˆåªåœ¨å‰å‡ æ­¥ï¼‰
        if t > T // 2:
            try:
                x_hat_list = photo_based_optimization_simple(
                    x_hat_list, input_image, zoom_stack, num_steps=2, lr=0.03
                )
            except Exception as e:
                print(f"    ä¼˜åŒ–å¤±è´¥: {e}")
        
        # èåˆ
        zoom_stack = multi_resolution_blending_simple(x_hat_list, zoom_stack)
    
    return zoom_stack


def test_photo_based_features():
    """æµ‹è¯•åŸºäºç…§ç‰‡çš„åŠŸèƒ½"""
    print("\n=== æµ‹è¯•åŸºäºç…§ç‰‡çš„åŠŸèƒ½ ===")
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥å›¾åƒ
    H, W = 32, 32
    input_image = torch.zeros((H, W, 3), device=device, dtype=torch.float32)
    
    # åˆ›å»ºç®€å•å›¾æ¡ˆ
    input_image[8:24, 8:24, 0] = 0.8
    input_image[10:22, 10:22, 1] = 0.6
    input_image[12:20, 12:20, 2] = 0.4
    
    print(f"åˆ›å»ºæµ‹è¯•å›¾åƒ: å½¢çŠ¶={input_image.shape}")
    
    # æµ‹è¯•åŸºäºç…§ç‰‡çš„é‡‡æ ·
    prompts = ["enhanced pattern", "artistic style"]
    zoom_factors = [1, 2]
    
    try:
        result = joint_sampling_with_photo_simple(
            prompts=prompts,
            zoom_factors=zoom_factors,
            input_image=input_image,
            T=3,  # å¿«é€Ÿæµ‹è¯•
            H=H, W=W
        )
        
        print("\nåŸºäºç…§ç‰‡çš„é‡‡æ ·å®Œæˆ!")
        result.print_info()
        
        # éªŒè¯ä¿æŒäº†è¾“å…¥ç‰¹å¾
        for i in range(len(zoom_factors)):
            layer = result.get_layer(i)
            input_mean = input_image.mean().item()
            layer_mean = layer.mean().item()
            print(f"å±‚ {i}: è¾“å…¥å‡å€¼={input_mean:.3f}, è¾“å‡ºå‡å€¼={layer_mean:.3f}")
        
        return True
        
    except Exception as e:
        print(f"åŸºäºç…§ç‰‡çš„é‡‡æ ·æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    print("=== Generative Powers of Ten - å®Œæ•´æµ‹è¯• ===")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    print("\nç¬¬ä¸€æ­¥ï¼šæµ‹è¯•æ¸²æŸ“å‡½æ•°")
    rendering_success = test_rendering_functions()
    
    if rendering_success:
        # æµ‹è¯•å¯è§†åŒ–æ¨¡å¼
        print("\nç¬¬äºŒæ­¥ï¼šæµ‹è¯•å¯è§†åŒ–æ¨¡å¼")
        test_visual_patterns()
        
        # æµ‹è¯•DDPMæ›´æ–°æ­¥éª¤
        print("\nç¬¬ä¸‰æ­¥ï¼šæµ‹è¯•DDPMæ›´æ–°æ­¥éª¤")
        ddpm_success = test_ddpm_update_simple()
        
        # æµ‹è¯•è”åˆé‡‡æ ·
        print("\nç¬¬å››æ­¥ï¼šæµ‹è¯•è”åˆå¤šå°ºåº¦é‡‡æ ·")
        sampling_success = test_joint_sampling()
        
        # æµ‹è¯•åŸºäºç…§ç‰‡çš„é‡‡æ ·
        print("\nç¬¬äº”æ­¥ï¼šæµ‹è¯•åŸºäºç…§ç‰‡çš„é‡‡æ ·")
        photo_success = test_photo_based_features()
        
        if ddpm_success and sampling_success and photo_success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•æˆåŠŸå®Œæˆ!")
            print("âœ… Pi_image å’Œ Pi_noise å‡½æ•°å·²æ­£ç¡®å®ç°ç®—æ³•1")
            print("âœ… æ”¯æŒå¤šå°ºåº¦å›¾åƒæ¸²æŸ“å’Œå™ªå£°ç”Ÿæˆ")
            print("âœ… åŒçº¿æ€§æ’å€¼å’Œæ©ç èåˆå·¥ä½œæ­£å¸¸")
            print("âœ… å™ªå£°åˆ†å¸ƒæ»¡è¶³ N(0,I) è¦æ±‚")
            print("âœ… DDPMæ›´æ–°æ­¥éª¤å·¥ä½œæ­£å¸¸")
            print("âœ… è”åˆå¤šå°ºåº¦é‡‡æ ·ï¼ˆç®—æ³•2ï¼‰å·¥ä½œæ­£å¸¸")
            print("âœ… 'Generative Powers of Ten' æ ¸å¿ƒç®—æ³•å®ç°å®Œæˆ!")
            
            print("\n=== ä¸»è¦åŠŸèƒ½æ€»ç»“ ===")
            print("1. ç¼©æ”¾æ ˆæ•°æ®ç»“æ„ (ZoomStack)")
            print("2. å›¾åƒæ¸²æŸ“å‡½æ•° (Pi_image)")
            print("3. å™ªå£°æ¸²æŸ“å‡½æ•° (Pi_noise)")
            print("4. DDPMæ›´æ–°æ­¥éª¤ (ddpm_update)")
            print("5. å¤šåˆ†è¾¨ç‡èåˆ (multi_resolution_blending)")
            print("6. è”åˆå¤šå°ºåº¦é‡‡æ · (joint_multi_scale_sampling)")
            print("7. åŸºäºç…§ç‰‡çš„ä¼˜åŒ– (photo_based_optimization)")
        else:
            print("\nâš ï¸  åŸºç¡€åŠŸèƒ½æµ‹è¯•æˆåŠŸï¼Œä½†é«˜çº§åŠŸèƒ½æµ‹è¯•éƒ¨åˆ†å¤±è´¥")
    else:
        print("\nâŒ æ¸²æŸ“å‡½æ•°æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°") 