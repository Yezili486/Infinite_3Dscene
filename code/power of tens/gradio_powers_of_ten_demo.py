#!/usr/bin/env python3
"""
Generative Powers of Ten - Interactive Gradio Demo

åŸºäºè®ºæ–‡ "Generative Powers of Ten" çš„äº¤äº’å¼æ¼”ç¤ºç•Œé¢
æ”¯æŒå¤šå°ºåº¦ç¼©æ”¾æ ˆç”Ÿæˆã€å®æ—¶å›¾åƒæµè§ˆå’ŒåŠ¨ç”»æ’­æ”¾

è¿è¡Œæ–¹å¼ï¼š
    python gradio_powers_of_ten_demo.py

ä¾èµ–åŒ…ï¼š
    pip install gradio torch torchvision opencv-python pillow numpy matplotlib
"""

import gradio as gr
import torch
import numpy as np
import cv2
import warnings
import time
import os
from PIL import Image
import matplotlib.pyplot as plt
from typing import List, Tuple, Optional
import threading
import math

warnings.filterwarnings("ignore")

# è®¾å¤‡é…ç½®
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# å…¨å±€å˜é‡å­˜å‚¨å½“å‰çš„ç¼©æ”¾æ ˆ
current_zoom_stack = None
generation_status = {"status": "idle", "progress": 0, "message": ""}

# ==================== æ ¸å¿ƒæ•°æ®ç»“æ„ ====================

class ZoomStack:
    """ç¼©æ”¾æ ˆæ•°æ®ç»“æ„"""
    
    def __init__(self, zoom_factors, H=512, W=512, device="cpu"):
        self.zoom_factors = zoom_factors
        self.N = len(zoom_factors)
        self.H = H
        self.W = W
        self.device = device
        
        # éªŒè¯ç¼©æ”¾å› å­
        for i, p in enumerate(zoom_factors):
            if i == 0:
                assert p == 1, "ç¬¬ä¸€ä¸ªç¼©æ”¾å› å­å¿…é¡»æ˜¯1"
            else:
                assert p == 2 * zoom_factors[i-1], f"ç¼©æ”¾å› å­å¿…é¡»æ˜¯2çš„å¹‚åºåˆ—ï¼Œç¬¬{i}ä¸ªå› å­{p}ä¸ç¬¦åˆè¦æ±‚"
        
        # åˆå§‹åŒ–å±‚
        self.layers = self._initialize_layers()
        
    def _initialize_layers(self):
        """åˆå§‹åŒ–æ‰€æœ‰å±‚"""
        layers = []
        for i, p in enumerate(self.zoom_factors):
            layer = torch.randn(self.H, self.W, 3, device=self.device, dtype=torch.float32)
            layer = layer * 0.1  # å‡å°åˆå§‹å™ªå£°å¹…åº¦
            layers.append(layer)
        return layers
    
    def get_layer(self, i):
        """è·å–ç¬¬ i å±‚"""
        assert 0 <= i < self.N, f"å±‚ç´¢å¼• {i} è¶…å‡ºèŒƒå›´ [0, {self.N-1}]"
        return self.layers[i]
    
    def set_layer(self, i, layer):
        """è®¾ç½®ç¬¬ i å±‚"""
        assert 0 <= i < self.N, f"å±‚ç´¢å¼• {i} è¶…å‡ºèŒƒå›´ [0, {self.N-1}]"
        assert layer.shape == (self.H, self.W, 3), f"å±‚å½¢çŠ¶å¿…é¡»æ˜¯ ({self.H}, {self.W}, 3)"
        self.layers[i] = layer.to(self.device)
    
    def get_zoom_factor(self, i):
        """è·å–ç¬¬ i å±‚çš„ç¼©æ”¾å› å­"""
        return self.zoom_factors[i]
    
    def get_all_layers(self):
        """è·å–æ‰€æœ‰å±‚çš„å‰¯æœ¬"""
        return [layer.clone() for layer in self.layers]
    
    def to_image_format(self, layer_idx):
        """å°†å±‚è½¬æ¢ä¸ºå›¾åƒæ ¼å¼ [0, 1]"""
        layer = self.get_layer(layer_idx)
        return torch.clamp((layer + 1.0) / 2.0, 0.0, 1.0)

def create_zoom_stack(zoom_factors, H=512, W=512, device="cpu"):
    """åˆ›å»ºç¼©æ”¾æ ˆçš„ä¾¿æ·å‡½æ•°"""
    return ZoomStack(zoom_factors, H, W, device)

def generate_zoom_factors(N):
    """ç”Ÿæˆ N ä¸ªç¼©æ”¾å› å­ï¼š[1, 2, 4, ..., 2^{N-1}]"""
    return [2**i for i in range(N)]

# ==================== æ¸²æŸ“å‡½æ•° ====================

def Pi_image(zoom_stack, i):
    """ä»ç¼©æ”¾æ ˆæ¸²æŸ“å›¾åƒï¼ˆç®—æ³• 1ï¼‰"""
    rendered = zoom_stack.get_layer(i).clone()
    H, W = rendered.shape[:2]
    p_i = zoom_stack.get_zoom_factor(i)
    
    # å¯¹äºæ‰€æœ‰æ›´é«˜å±‚ï¼Œä¸‹é‡‡æ ·å¹¶èåˆ
    for j in range(i + 1, zoom_stack.N):
        layer_j = zoom_stack.get_layer(j)
        p_j = zoom_stack.get_zoom_factor(j)
        
        # ä¸­å¿ƒè£å‰ª
        crop_h = max(1, H // p_j)
        crop_w = max(1, W // p_j)
        start_h = (H - crop_h) // 2
        start_w = (W - crop_w) // 2
        end_h = start_h + crop_h
        end_w = start_w + crop_w
        
        cropped_j = layer_j[start_h:end_h, start_w:end_w, :]
        
        # ä¸Šé‡‡æ ·
        if crop_h != H or crop_w != W:
            cropped_j_chw = cropped_j.permute(2, 0, 1).unsqueeze(0)
            upsampled_j = torch.nn.functional.interpolate(
                cropped_j_chw, 
                size=(H, W), 
                mode='bilinear', 
                align_corners=False
            )
            upsampled_j = upsampled_j.squeeze(0).permute(1, 2, 0)
        else:
            upsampled_j = cropped_j
        
        # èåˆæ©ç ï¼ˆä¸­å¿ƒåŒºåŸŸï¼‰
        mask = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
        mask_h_start = (H - crop_h * p_j) // 2
        mask_w_start = (W - crop_w * p_j) // 2
        mask_h_end = min(H, mask_h_start + crop_h * p_j)
        mask_w_end = min(W, mask_w_start + crop_w * p_j)
        
        if mask_h_end > mask_h_start and mask_w_end > mask_w_start:
            mask[mask_h_start:mask_h_end, mask_w_start:mask_w_end, :] = 1.0
        
        rendered = rendered * (1 - mask) + upsampled_j * mask
    
    return rendered

def Pi_noise(zoom_stack, i):
    """ä»ç¼©æ”¾æ ˆæ¸²æŸ“å™ªå£°ï¼ˆç®—æ³• 1ï¼‰"""
    H, W = zoom_stack.H, zoom_stack.W
    rendered_noise = torch.zeros((H, W, 3), device=zoom_stack.device, dtype=torch.float32)
    p_i = zoom_stack.get_zoom_factor(i)
    total_variance = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
    
    for j in range(i, zoom_stack.N):
        p_j = zoom_stack.get_zoom_factor(j)
        noise_scale = p_j / p_i
        
        if j == i:
            layer_noise = torch.randn((H, W, 3), device=zoom_stack.device, dtype=torch.float32)
            layer_noise *= noise_scale
            mask = torch.ones((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
        else:
            crop_h = max(1, H // p_j)
            crop_w = max(1, W // p_j)
            
            cropped_noise = torch.randn((crop_h, crop_w, 3), device=zoom_stack.device, dtype=torch.float32)
            cropped_noise *= noise_scale
            
            cropped_noise_chw = cropped_noise.permute(2, 0, 1).unsqueeze(0)
            upsampled_noise = torch.nn.functional.interpolate(
                cropped_noise_chw,
                size=(H, W),
                mode='bilinear',
                align_corners=False
            )
            layer_noise = upsampled_noise.squeeze(0).permute(1, 2, 0)
            
            mask = torch.zeros((H, W, 1), device=zoom_stack.device, dtype=torch.float32)
            mask_h_start = (H - crop_h * p_j) // 2
            mask_w_start = (W - crop_w * p_j) // 2
            mask_h_end = min(H, mask_h_start + crop_h * p_j)
            mask_w_end = min(W, mask_w_start + crop_w * p_j)
            
            if mask_h_end > mask_h_start and mask_w_end > mask_w_start:
                mask[mask_h_start:mask_h_end, mask_w_start:mask_w_end, :] = 1.0
            
            layer_noise = layer_noise * mask
        
        rendered_noise += layer_noise
        total_variance += mask * (noise_scale ** 2)
    
    std_dev = torch.sqrt(total_variance + 1e-8)
    rendered_noise = rendered_noise / std_dev
    
    return rendered_noise

# ==================== ç®€åŒ–çš„ç”Ÿæˆå‡½æ•° ====================

def create_artistic_pattern(prompt, H, W, scale_index, total_scales):
    """åŸºäºæç¤ºåˆ›å»ºè‰ºæœ¯å›¾æ¡ˆï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä¸éœ€è¦AIæ¨¡å‹ï¼‰"""
    pattern = torch.zeros((H, W, 3), dtype=torch.float32)
    
    # æ ¹æ®æç¤ºå…³é”®è¯åˆ›å»ºä¸åŒçš„å›¾æ¡ˆ
    prompt_lower = prompt.lower()
    
    # åˆ›å»ºåŸºç¡€åæ ‡ç½‘æ ¼
    y_coords, x_coords = torch.meshgrid(
        torch.linspace(-1, 1, H), 
        torch.linspace(-1, 1, W), 
        indexing='ij'
    )
    r = torch.sqrt(x_coords**2 + y_coords**2)
    theta = torch.atan2(y_coords, x_coords)
    
    # æ ¹æ®ä¸åŒå…³é”®è¯ç”Ÿæˆä¸åŒå›¾æ¡ˆ
    if any(word in prompt_lower for word in ['galaxy', 'spiral', 'cosmic', 'space']):
        # èºæ—‹æ˜Ÿç³»å›¾æ¡ˆ
        spiral = torch.sin(3 * theta + 5 * r) * torch.exp(-r * 2)
        pattern[:, :, 0] = 0.3 + 0.4 * spiral  # çº¢è‰²
        pattern[:, :, 1] = 0.1 + 0.2 * spiral  # ç»¿è‰²
        pattern[:, :, 2] = 0.6 + 0.3 * spiral  # è“è‰²
        
    elif any(word in prompt_lower for word in ['star', 'system', 'planet']):
        # è¡Œæ˜Ÿç³»ç»Ÿå›¾æ¡ˆ
        for i in range(3):
            orbit_radius = 0.2 + i * 0.3
            orbit = torch.exp(-((r - orbit_radius) ** 2) / 0.01)
            pattern[:, :, i] = 0.2 + 0.5 * orbit
            
    elif any(word in prompt_lower for word in ['surface', 'mountain', 'terrain', 'landscape']):
        # åœ°å½¢å›¾æ¡ˆ
        terrain = torch.sin(x_coords * 8) * torch.sin(y_coords * 6) * torch.exp(-r)
        pattern[:, :, 0] = 0.4 + 0.3 * terrain  # åœŸåœ°è‰²
        pattern[:, :, 1] = 0.3 + 0.4 * terrain  # ç»¿è‰²
        pattern[:, :, 2] = 0.2 + 0.2 * terrain  # è“è‰²
        
    elif any(word in prompt_lower for word in ['tree', 'forest', 'branch', 'bark']):
        # æ ‘æœ¨/æ£®æ—å›¾æ¡ˆ
        tree_pattern = torch.sin(y_coords * 10) * torch.cos(x_coords * 8)
        pattern[:, :, 0] = 0.2 + 0.3 * torch.abs(tree_pattern)  # æ£•è‰²
        pattern[:, :, 1] = 0.4 + 0.4 * torch.abs(tree_pattern)  # ç»¿è‰²
        pattern[:, :, 2] = 0.1 + 0.2 * torch.abs(tree_pattern)  # è“è‰²
        
    elif any(word in prompt_lower for word in ['insect', 'bug', 'detail', 'micro']):
        # å¾®è§‚ç»†èŠ‚å›¾æ¡ˆ
        detail = torch.sin(x_coords * 20) * torch.sin(y_coords * 20) * torch.exp(-r * 0.5)
        pattern[:, :, 0] = 0.5 + 0.3 * detail
        pattern[:, :, 1] = 0.3 + 0.4 * detail
        pattern[:, :, 2] = 0.2 + 0.3 * detail
        
    elif any(word in prompt_lower for word in ['ocean', 'water', 'wave', 'sea']):
        # æµ·æ´‹å›¾æ¡ˆ
        waves = torch.sin(x_coords * 6 + theta * 3) * torch.cos(y_coords * 4)
        pattern[:, :, 0] = 0.1 + 0.2 * torch.abs(waves)  # çº¢è‰²ï¼ˆå°‘ï¼‰
        pattern[:, :, 1] = 0.3 + 0.3 * torch.abs(waves)  # ç»¿è‰²
        pattern[:, :, 2] = 0.6 + 0.3 * torch.abs(waves)  # è“è‰²ï¼ˆæµ·æ´‹è‰²ï¼‰
        
    elif any(word in prompt_lower for word in ['coral', 'reef', 'underwater']):
        # çŠç‘šç¤å›¾æ¡ˆ
        coral = torch.sin(r * 15) * torch.cos(theta * 8) * torch.exp(-r)
        pattern[:, :, 0] = 0.6 + 0.3 * coral  # çŠç‘šè‰²
        pattern[:, :, 1] = 0.2 + 0.4 * coral
        pattern[:, :, 2] = 0.4 + 0.3 * coral
        
    elif any(word in prompt_lower for word in ['fish', 'tropical', 'close']):
        # é±¼ç±»å›¾æ¡ˆ
        fish_body = torch.exp(-((x_coords - 0.2)**2 + y_coords**2) / 0.1)
        pattern[:, :, 0] = 0.7 + 0.2 * fish_body  # æ©™è‰²
        pattern[:, :, 1] = 0.5 + 0.3 * fish_body  # é»„è‰²
        pattern[:, :, 2] = 0.2 + 0.2 * fish_body
        
    else:
        # é»˜è®¤æŠ½è±¡å›¾æ¡ˆ
        default_pattern = torch.sin(r * 10 + theta * scale_index)
        pattern[:, :, 0] = 0.5 + 0.3 * default_pattern
        pattern[:, :, 1] = 0.4 + 0.3 * default_pattern
        pattern[:, :, 2] = 0.3 + 0.4 * default_pattern
    
    # æ·»åŠ å™ªå£°ä»¥å¢åŠ çœŸå®æ„Ÿ
    noise = torch.randn_like(pattern) * 0.05
    pattern += noise
    
    # æ ¹æ®ç¼©æ”¾çº§åˆ«è°ƒæ•´ç»†èŠ‚
    detail_factor = 1.0 + scale_index * 0.5
    pattern *= detail_factor
    
    # é™åˆ¶åˆ°[-1, 1]èŒƒå›´
    pattern = torch.clamp(pattern * 2 - 1, -1, 1)
    
    return pattern

def joint_multi_scale_sampling_demo(prompts, zoom_factors, T=15, H=512, W=512):
    """æ¼”ç¤ºç‰ˆæœ¬çš„è”åˆå¤šå°ºåº¦é‡‡æ ·ï¼ˆæ— éœ€AIæ¨¡å‹ï¼‰"""
    global generation_status
    
    generation_status["status"] = "generating"
    generation_status["progress"] = 0
    generation_status["message"] = "åˆå§‹åŒ–ç¼©æ”¾æ ˆ..."
    
    N = len(prompts)
    zoom_stack = create_zoom_stack(zoom_factors, H, W, device)
    
    # ç”Ÿæˆåˆå§‹å›¾æ¡ˆ
    for i, prompt in enumerate(prompts):
        generation_status["progress"] = int((i / N) * 30)
        generation_status["message"] = f"ç”Ÿæˆç¬¬ {i+1}/{N} å±‚å›¾æ¡ˆ..."
        
        # åˆ›å»ºåŸºäºæç¤ºçš„è‰ºæœ¯å›¾æ¡ˆ
        initial_pattern = create_artistic_pattern(prompt, H, W, i, N)
        zoom_stack.set_layer(i, initial_pattern)
        
        time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    # ç®€åŒ–çš„æ‰©æ•£å¾ªç¯ï¼ˆå¤šå°ºåº¦ä¼˜åŒ–ï¼‰
    for t in range(T, 0, -1):
        progress = (T - t + 1) / T
        generation_status["progress"] = int(30 + progress * 70)
        generation_status["message"] = f"å¤šå°ºåº¦ä¼˜åŒ–æ­¥éª¤ {T-t+1}/{T}"
        
        # æ¸²æŸ“å½“å‰çŠ¶æ€
        for i in range(N):
            img_rendered = Pi_image(zoom_stack, i)
            noise_rendered = Pi_noise(zoom_stack, i)
            
            # æ·»åŠ æ¸è¿›å¼ä¼˜åŒ–
            noise_level = t / T * 0.2  # å‡å°å™ªå£°å¼ºåº¦
            denoising_strength = progress * 0.5
            
            # æ··åˆä¼˜åŒ–
            base_img = zoom_stack.get_layer(i)
            optimized = (base_img * (1 - denoising_strength) + 
                        img_rendered * denoising_strength * 0.7 +
                        noise_rendered * noise_level * 0.1)
            
            zoom_stack.set_layer(i, optimized)
        
        time.sleep(0.05)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    generation_status["status"] = "completed"
    generation_status["progress"] = 100
    generation_status["message"] = "ç”Ÿæˆå®Œæˆ!"
    
    return zoom_stack

# ==================== Gradio ç•Œé¢å‡½æ•° ====================

def tensor_to_pil(tensor):
    """å°†PyTorchå¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ"""
    # è½¬æ¢åˆ°[0, 1]èŒƒå›´
    img_tensor = torch.clamp((tensor + 1.0) / 2.0, 0.0, 1.0)
    # è½¬æ¢ä¸ºnumpy
    img_numpy = (img_tensor.cpu().numpy() * 255).astype(np.uint8)
    # è½¬æ¢ä¸ºPILå›¾åƒ
    pil_img = Image.fromarray(img_numpy)
    return pil_img

def parse_prompts(prompts_text):
    """è§£ææç¤ºæ–‡æœ¬"""
    if not prompts_text.strip():
        return []
    
    # æŒ‰è¡Œåˆ†å‰²æˆ–æŒ‰é€—å·åˆ†å‰²
    if '\n' in prompts_text:
        prompts = [p.strip() for p in prompts_text.split('\n') if p.strip()]
    else:
        prompts = [p.strip() for p in prompts_text.split(',') if p.strip()]
    
    return prompts

def parse_zoom_factors(zoom_factors_text):
    """è§£æç¼©æ”¾å› å­"""
    try:
        if not zoom_factors_text.strip():
            return []
        
        # æ”¯æŒå¤šç§æ ¼å¼
        zoom_factors_text = zoom_factors_text.replace('[', '').replace(']', '').replace('(', '').replace(')', '')
        factors = [int(f.strip()) for f in zoom_factors_text.split(',') if f.strip()]
        
        # éªŒè¯æ˜¯å¦æ˜¯2çš„å¹‚åºåˆ—
        if factors and factors[0] != 1:
            raise ValueError("ç¬¬ä¸€ä¸ªç¼©æ”¾å› å­å¿…é¡»æ˜¯1")
        
        for i in range(1, len(factors)):
            if factors[i] != 2 * factors[i-1]:
                raise ValueError(f"ç¼©æ”¾å› å­å¿…é¡»æ˜¯2çš„å¹‚åºåˆ—ï¼Œç¬¬{i}ä¸ªå› å­{factors[i]}ä¸ç¬¦åˆè¦æ±‚")
        
        return factors
    except Exception as e:
        raise ValueError(f"ç¼©æ”¾å› å­æ ¼å¼é”™è¯¯: {e}")

def generate_zoom_stack_ui(prompts_text, zoom_factors_text, progress=gr.Progress()):
    """ç”Ÿæˆç¼©æ”¾æ ˆï¼ˆUIæ¥å£ï¼‰"""
    global current_zoom_stack
    
    try:
        # è§£æè¾“å…¥
        prompts = parse_prompts(prompts_text)
        zoom_factors = parse_zoom_factors(zoom_factors_text)
        
        if not prompts:
            return "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæç¤º", None, gr.update(visible=False)
        
        if not zoom_factors:
            return "âŒ é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆçš„ç¼©æ”¾å› å­", None, gr.update(visible=False)
        
        if len(prompts) != len(zoom_factors):
            return f"âŒ é”™è¯¯ï¼šæç¤ºæ•°é‡({len(prompts)})ä¸ç¼©æ”¾å› å­æ•°é‡({len(zoom_factors)})ä¸åŒ¹é…", None, gr.update(visible=False)
        
        # ç”Ÿæˆç¼©æ”¾æ ˆ
        progress(0, desc="å¼€å§‹ç”Ÿæˆ...")
        
        # ä½¿ç”¨çº¿ç¨‹æ¥ç›‘æ§è¿›åº¦
        def monitor_progress():
            while generation_status["status"] == "generating":
                progress(generation_status["progress"] / 100, desc=generation_status["message"])
                time.sleep(0.1)
        
        monitor_thread = threading.Thread(target=monitor_progress)
        monitor_thread.start()
        
        current_zoom_stack = joint_multi_scale_sampling_demo(
            prompts=prompts,
            zoom_factors=zoom_factors,
            T=15,  # å‡å°‘æ­¥æ•°ä»¥æé«˜äº¤äº’æ€§
            H=512, W=512
        )
        
        monitor_thread.join()
        progress(1.0, desc="ç”Ÿæˆå®Œæˆ!")
        
        # è¿”å›ç¬¬ä¸€å±‚å›¾åƒä½œä¸ºé¢„è§ˆ
        first_layer_img = Pi_image(current_zoom_stack, 0)
        preview_img = tensor_to_pil(first_layer_img)
        
        # æ›´æ–°æ»‘å—èŒƒå›´
        slider_update = gr.update(
            minimum=0, 
            maximum=len(zoom_factors)-1, 
            value=0, 
            step=1,
            visible=True,
            label=f"ç¼©æ”¾çº§åˆ« (0-{len(zoom_factors)-1})"
        )
        
        return f"âœ… æˆåŠŸç”Ÿæˆ {len(zoom_factors)} å±‚ç¼©æ”¾æ ˆï¼", preview_img, slider_update
        
    except Exception as e:
        return f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}", None, gr.update(visible=False)

def render_scale_image(scale_idx):
    """æ¸²æŸ“æŒ‡å®šå°ºåº¦çš„å›¾åƒ"""
    global current_zoom_stack
    
    if current_zoom_stack is None:
        return None, "è¯·å…ˆç”Ÿæˆç¼©æ”¾æ ˆ"
    
    try:
        scale_idx = int(scale_idx)
        if scale_idx < 0 or scale_idx >= current_zoom_stack.N:
            return None, f"å°ºåº¦ç´¢å¼•è¶…å‡ºèŒƒå›´ (0-{current_zoom_stack.N-1})"
        
        # æ¸²æŸ“å›¾åƒ
        rendered_img = Pi_image(current_zoom_stack, scale_idx)
        pil_img = tensor_to_pil(rendered_img)
        
        zoom_factor = current_zoom_stack.get_zoom_factor(scale_idx)
        info_text = f"å°ºåº¦ {scale_idx}: ç¼©æ”¾å› å­ {zoom_factor}x (åˆ†è¾¨ç‡: {current_zoom_stack.H}x{current_zoom_stack.W})"
        
        return pil_img, info_text
        
    except Exception as e:
        return None, f"æ¸²æŸ“å¤±è´¥: {str(e)}"

def create_zoom_animation():
    """åˆ›å»ºç¼©æ”¾åŠ¨ç”»"""
    global current_zoom_stack
    
    if current_zoom_stack is None:
        return None, "è¯·å…ˆç”Ÿæˆç¼©æ”¾æ ˆ"
    
    try:
        print("å¼€å§‹åˆ›å»ºç¼©æ”¾åŠ¨ç”»...")
        
        # åˆ›å»ºåŠ¨ç”»å¸§
        frames = []
        for i in range(current_zoom_stack.N):
            rendered_img = Pi_image(current_zoom_stack, i)
            pil_img = tensor_to_pil(rendered_img)
            frames.append(pil_img)
        
        # ä¿å­˜ä¸ºGIF
        if frames:
            output_path = "zoom_animation.gif"
            frames[0].save(
                output_path,
                save_all=True,
                append_images=frames[1:],
                duration=1500,  # æ¯å¸§1.5ç§’
                loop=0
            )
            
            print(f"åŠ¨ç”»å·²ä¿å­˜: {output_path}")
            return output_path, f"âœ… åŠ¨ç”»å·²åˆ›å»ºï¼ŒåŒ…å« {len(frames)} å¸§ (æ¯å¸§1.5ç§’)"
        else:
            return None, "âŒ æ— æ³•åˆ›å»ºåŠ¨ç”»å¸§"
            
    except Exception as e:
        print(f"åŠ¨ç”»åˆ›å»ºå¤±è´¥: {e}")
        return None, f"âŒ åŠ¨ç”»åˆ›å»ºå¤±è´¥: {str(e)}"

def get_example_inputs():
    """è·å–ç¤ºä¾‹è¾“å…¥"""
    examples = {
        "cosmic": {
            "prompts": "distant galaxy with swirling spiral arms\nstar system with multiple planets\nplanet surface with mountains\nclose-up of alien vegetation",
            "zoom_factors": "1, 2, 4, 8"
        },
        "nature": {
            "prompts": "vast forest landscape\ntree with many branches\nbark texture detail\ninsect on bark surface",
            "zoom_factors": "1, 2, 4, 8"
        },
        "ocean": {
            "prompts": "ocean from space\nocean surface with waves\nunderwater coral reef\ntropical fish close-up",
            "zoom_factors": "1, 2, 4, 8"
        },
        "simple": {
            "prompts": "abstract art\ncolorful pattern\ngeometric design",
            "zoom_factors": "1, 2, 4"
        }
    }
    return examples

# ==================== Gradio ç•Œé¢ ====================

def create_gradio_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(
        title="Generative Powers of Ten - Interactive Demo",
        theme=gr.themes.Soft(),
        css="""
        .main-container { max-width: 1200px; margin: auto; }
        .header { text-align: center; margin-bottom: 2rem; }
        .status-text { font-weight: bold; }
        .example-btn { margin: 2px; }
        """
    ) as demo:
        
        # æ ‡é¢˜å’Œè¯´æ˜
        gr.HTML("""
        <div class="header">
            <h1>ğŸ” Generative Powers of Ten - Interactive Demo</h1>
            <p>åŸºäºè®ºæ–‡ "Generative Powers of Ten" çš„äº¤äº’å¼æ¼”ç¤º</p>
            <p>è¾“å…¥æ–‡æœ¬æç¤ºç”Ÿæˆå¤šå°ºåº¦ç¼©æ”¾æ ˆï¼Œå¹¶å®æ—¶æµè§ˆä¸åŒç¼©æ”¾çº§åˆ«çš„å›¾åƒ</p>
            <p><em>æ¼”ç¤ºç‰ˆæœ¬ï¼šä½¿ç”¨ç¨‹åºåŒ–å›¾æ¡ˆç”Ÿæˆï¼Œæ— éœ€ä¸‹è½½AIæ¨¡å‹</em></p>
        </div>
        """)
        
        with gr.Row():
            # å·¦ä¾§ï¼šè¾“å…¥æ§åˆ¶é¢æ¿
            with gr.Column(scale=1):
                gr.Markdown("## ğŸ“ è¾“å…¥é…ç½®")
                
                prompts_input = gr.Textbox(
                    label="æ–‡æœ¬æç¤º (æ¯è¡Œä¸€ä¸ªæˆ–é€—å·åˆ†éš”)",
                    placeholder="ä¾‹å¦‚ï¼š\ndistant galaxy\nstar system\nplanet surface\ninsect detail",
                    lines=6,
                    value="distant galaxy with swirling spiral arms\nstar system with multiple planets\nplanet surface with mountains\nclose-up of alien vegetation"
                )
                
                zoom_factors_input = gr.Textbox(
                    label="ç¼©æ”¾å› å­ (2çš„å¹‚åºåˆ—ï¼Œé€—å·åˆ†éš”)",
                    placeholder="ä¾‹å¦‚ï¼š1, 2, 4, 8",
                    value="1, 2, 4, 8"
                )
                
                generate_btn = gr.Button("ğŸš€ ç”Ÿæˆç¼©æ”¾æ ˆ", variant="primary", size="lg")
                
                status_text = gr.Textbox(
                    label="çŠ¶æ€",
                    value="å‡†å¤‡å°±ç»ª - ç‚¹å‡»ç”ŸæˆæŒ‰é’®å¼€å§‹",
                    interactive=False,
                    elem_classes=["status-text"]
                )
                
                # ç¤ºä¾‹æŒ‰é’®
                gr.Markdown("### ğŸ¯ å¿«é€Ÿç¤ºä¾‹")
                examples = get_example_inputs()
                
                with gr.Row():
                    cosmic_btn = gr.Button("ğŸŒŒ å®‡å®™ç¼©æ”¾", size="sm", elem_classes=["example-btn"])
                    nature_btn = gr.Button("ğŸŒ³ è‡ªç„¶ç¼©æ”¾", size="sm", elem_classes=["example-btn"])
                
                with gr.Row():
                    ocean_btn = gr.Button("ğŸŒŠ æµ·æ´‹ç¼©æ”¾", size="sm", elem_classes=["example-btn"])
                    simple_btn = gr.Button("ğŸ¨ ç®€å•ç¤ºä¾‹", size="sm", elem_classes=["example-btn"])
            
            # å³ä¾§ï¼šæ˜¾ç¤ºé¢æ¿
            with gr.Column(scale=2):
                gr.Markdown("## ğŸ–¼ï¸ å›¾åƒæ˜¾ç¤º")
                
                # ä¸»å›¾åƒæ˜¾ç¤º
                main_image = gr.Image(
                    label="å½“å‰å°ºåº¦å›¾åƒ",
                    type="pil",
                    height=400,
                    show_download_button=True
                )
                
                # ç¼©æ”¾çº§åˆ«æ§åˆ¶
                scale_slider = gr.Slider(
                    minimum=0,
                    maximum=3,
                    value=0,
                    step=1,
                    label="ç¼©æ”¾çº§åˆ«",
                    visible=False,
                    interactive=True
                )
                
                scale_info = gr.Textbox(
                    label="å°ºåº¦ä¿¡æ¯",
                    value="",
                    interactive=False
                )
                
                # åŠ¨ç”»æ§åˆ¶
                gr.Markdown("### ğŸ¬ ç¼©æ”¾åŠ¨ç”»")
                with gr.Row():
                    animation_btn = gr.Button("â–¶ï¸ åˆ›å»ºç¼©æ”¾åŠ¨ç”»", variant="secondary")
                
                animation_output = gr.File(
                    label="åŠ¨ç”»æ–‡ä»¶ (GIF)",
                    visible=False
                )
                
                animation_status = gr.Textbox(
                    label="åŠ¨ç”»çŠ¶æ€",
                    value="",
                    interactive=False
                )
        
        # äº‹ä»¶ç»‘å®š
        
        # ç”Ÿæˆç¼©æ”¾æ ˆ
        generate_btn.click(
            fn=generate_zoom_stack_ui,
            inputs=[prompts_input, zoom_factors_input],
            outputs=[status_text, main_image, scale_slider]
        )
        
        # æ»‘å—å˜åŒ–æ—¶é‡æ–°æ¸²æŸ“
        scale_slider.change(
            fn=render_scale_image,
            inputs=[scale_slider],
            outputs=[main_image, scale_info]
        )
        
        # åˆ›å»ºåŠ¨ç”»
        animation_btn.click(
            fn=create_zoom_animation,
            outputs=[animation_output, animation_status]
        ).then(
            lambda: gr.update(visible=True),
            outputs=[animation_output]
        )
        
        # ç¤ºä¾‹æŒ‰é’®äº‹ä»¶
        cosmic_btn.click(
            lambda: (examples["cosmic"]["prompts"], examples["cosmic"]["zoom_factors"]),
            outputs=[prompts_input, zoom_factors_input]
        )
        
        nature_btn.click(
            lambda: (examples["nature"]["prompts"], examples["nature"]["zoom_factors"]),
            outputs=[prompts_input, zoom_factors_input]
        )
        
        ocean_btn.click(
            lambda: (examples["ocean"]["prompts"], examples["ocean"]["zoom_factors"]),
            outputs=[prompts_input, zoom_factors_input]
        )
        
        simple_btn.click(
            lambda: (examples["simple"]["prompts"], examples["simple"]["zoom_factors"]),
            outputs=[prompts_input, zoom_factors_input]
        )
        
        # åº•éƒ¨è¯´æ˜
        gr.HTML("""
        <div style="margin-top: 2rem; padding: 1rem; background-color: #f0f0f0; border-radius: 8px;">
            <h3>ğŸ“– ä½¿ç”¨è¯´æ˜</h3>
            <ul>
                <li><strong>æ–‡æœ¬æç¤º</strong>ï¼šè¾“å…¥æè¿°ä¸åŒå°ºåº¦çš„æ–‡æœ¬ï¼Œä»æœ€å¤§å°ºåº¦åˆ°æœ€å°å°ºåº¦</li>
                <li><strong>ç¼©æ”¾å› å­</strong>ï¼šå¿…é¡»æ˜¯2çš„å¹‚åºåˆ—ï¼Œå¦‚ 1, 2, 4, 8</li>
                <li><strong>ç”Ÿæˆ</strong>ï¼šç‚¹å‡»ç”ŸæˆæŒ‰é’®åˆ›å»ºç¼©æ”¾æ ˆï¼ˆçº¦éœ€30-60ç§’ï¼‰</li>
                <li><strong>æµè§ˆ</strong>ï¼šä½¿ç”¨æ»‘å—å®æ—¶æŸ¥çœ‹ä¸åŒç¼©æ”¾çº§åˆ«çš„å›¾åƒ</li>
                <li><strong>åŠ¨ç”»</strong>ï¼šåˆ›å»ºä»ç²—åˆ°ç»†çš„ç¼©æ”¾åŠ¨ç”»GIFæ–‡ä»¶</li>
            </ul>
            
            <h3>ğŸ¨ æ”¯æŒçš„å›¾æ¡ˆå…³é”®è¯</h3>
            <p><strong>å®‡å®™ç³»åˆ—</strong>ï¼šgalaxy, spiral, cosmic, space, star, system, planet</p>
            <p><strong>è‡ªç„¶ç³»åˆ—</strong>ï¼šsurface, mountain, terrain, tree, forest, branch, bark, insect</p>
            <p><strong>æµ·æ´‹ç³»åˆ—</strong>ï¼šocean, water, wave, coral, reef, underwater, fish, tropical</p>
            
            <h3>âš ï¸ æ³¨æ„äº‹é¡¹</h3>
            <p>â€¢ è¿™æ˜¯æ¼”ç¤ºç‰ˆæœ¬ï¼Œä½¿ç”¨ç¨‹åºåŒ–å›¾æ¡ˆç”Ÿæˆï¼Œä¸éœ€è¦ä¸‹è½½AIæ¨¡å‹</p>
            <p>â€¢ æ”¯æŒCPUå’ŒGPUè¿è¡Œï¼Œé¦–æ¬¡ä½¿ç”¨æ—¶å¯èƒ½éœ€è¦å®‰è£…ä¾èµ–åŒ…</p>
            <p>â€¢ ç”Ÿæˆçš„å›¾åƒåŸºäºæ•°å­¦å‡½æ•°ï¼Œæä¾›"Generative Powers of Ten"ç®—æ³•çš„æ¦‚å¿µæ¼”ç¤º</p>
        </div>
        """)
    
    return demo

# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    print("=== Generative Powers of Ten - Gradio Interface ===")
    print(f"è®¾å¤‡: {device}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import gradio
        print(f"Gradioç‰ˆæœ¬: {gradio.__version__}")
    except ImportError:
        print("âŒ é”™è¯¯ï¼šè¯·å®‰è£…Gradio - pip install gradio")
        return
    
    print("âœ… å‡†å¤‡å°±ç»ª")
    print("ğŸ¯ æ¼”ç¤ºæ¨¡å¼ï¼šä½¿ç”¨ç¨‹åºåŒ–å›¾æ¡ˆç”Ÿæˆï¼Œæ— éœ€AIæ¨¡å‹")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    demo = create_gradio_interface()
    
    print("\nğŸš€ å¯åŠ¨GradioæœåŠ¡å™¨...")
    print("   - æœ¬åœ°è®¿é—®: http://localhost:7860")
    print("   - æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    
    # å¯åŠ¨æœåŠ¡å™¨
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,       # ç«¯å£å·
        share=False,            # è®¾ä¸ºTrueå¯åˆ›å»ºä¸´æ—¶å…¬å…±URL
        debug=False,            # è°ƒè¯•æ¨¡å¼
        show_error=True,        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        quiet=False             # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    )

if __name__ == "__main__":
    main() 